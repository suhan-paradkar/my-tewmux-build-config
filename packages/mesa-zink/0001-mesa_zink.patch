This patch is intended to apply for https://gitlab.freedesktop.org/mesa/mesa.git, branch "main", "git checkout b8970120545b3cb250821013cb459bf4d2acfda4"
It primarily reverts some changes related to 8724d4fb36 and c1cdf30a11.

 ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------

Thanks https://github.com/Grima04/mesa-turnip-kgsl for modifications of egldisplay.h and install_megadrivers.py

 ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
 
Contains parts of:

Mesa - Copyright (C) 1999-2007  Brian Paul   All Rights Reserved.
install_megadrivers.py - Copyright 2017-2018 Intel Corporation
src/gallium/auxiliary/meson.build - Copyright © 2017 Dylan Baker
src/gallium/targets/libgl-xlib/meson.build - Copyright © 2017 Intel Corporation
meson_options.txt - Copyright © 2017-2019 Intel Corporation
meson.build - Copyright © 2017-2020 Intel Corporation

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"),
to deal in the Software without restriction, including without limitation
the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

egldisplay.h -  * Copyright 2008 VMware, Inc.
 * Copyright 2009-2010 Chia-I Wu <olvaffe@gmail.com>
 * Copyright 2010-2011 LunarG, Inc.
 * All Rights Reserved.
nir.h - Copyright © 2014 Connor Abbott
src/compiler/nir/nir_lower_uniforms_to_ubo.c - Copyright 2017 Advanced Micro Devices, Inc.
draw_vs_llvm.c - Copyright 2010 VMware, Inc.
All Rights Reserved.
nir_to_tgsi.c - Copyright © 2014-2015 Broadcom
tgsi_to_nir.c - Copyright © 2014-2015 Broadcom
Copyright (C) 2014 Rob Clark <robclark@freedesktop.org>
d3d12_compiler.cpp - Copyright © Microsoft Corporation
nir_lower_dynamic_bo_access.c - Copyright © 2020 Mike Blumenkrantz
nir_to_spirv.c zink_compiler.c zink_compiler.h zink_context.c zink_context.h zink_pipeline.c zink_pipeline.h zink_program.c zink_program.h zink_screen.c zink_screen.h zink_state.c zink_state.h - Copyright 2018 Collabora Ltd.
st_glsl_to_nir.cpp - Copyright © 2015 Red Hat

 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * on the rights to use, copy, modify, merge, publish, distribute, sub
 * license, and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
diff --git a/bin/install_megadrivers.py b/bin/install_megadrivers.py
index 0a28dd7c0c5..2c6ab2602f3 100644
--- a/bin/install_megadrivers.py
+++ b/bin/install_megadrivers.py
@@ -24,7 +24,15 @@
 
 from __future__ import print_function
 import argparse
-import os
+import os, shutil
+def link(src, dest):
+    shutil.copyfile(src, dest)
+
+def unlink(src):
+    os.remove(src)
+
+os.link = link
+os.unlink = unlink
 
 
 def main():
diff --git a/meson.build b/meson.build
index 00bf9cc1456..a95c211765c 100644
--- a/meson.build
+++ b/meson.build
@@ -26,11 +26,16 @@ project(
   ).stdout(),
   license : 'MIT',
   meson_version : '>= 0.52',
-  default_options : ['buildtype=debugoptimized', 'b_ndebug=if-release', 'c_std=c99', 'cpp_std=c++14']
+  default_options : ['buildtype=debugoptimized', 'b_ndebug=if-release', 'c_std=c99', 'cpp_std=c++14', 'prefix=/data/data/com.termux/files/usr']
 )
 
 cc = meson.get_compiler('c')
 cpp = meson.get_compiler('cpp')
+dep_a = cc.find_library('android-shmem', required : false, static : true)
+if not dep_a.found()
+  error('use pkg install libandroid-shmem-static')
+endif
+dep_l = cc.find_library('log', required : true, static : false)
 
 null_dep = dependency('', required : false)
 
@@ -1853,7 +1858,14 @@ endif
 # TODO: symbol mangling
 
 if with_platform_wayland
-  dep_wl_scanner = dependency('wayland-scanner', native: true)
+  dep_wl_scanner = dependency('wayland-scanner', native: true, required : false, version : '>=1.18')
+  if not dep_wl_scanner.found()
+      warning('wayland-scanner (https://gitlab.freedesktop.org/wayland/wayland) not installed or outdated, disabling wayland')
+      with_platform_wayland = false
+  endif
+endif
+
+if with_platform_wayland
   prog_wl_scanner = find_program(dep_wl_scanner.get_pkgconfig_variable('wayland_scanner'))
   if dep_wl_scanner.version().version_compare('>= 1.15')
     wl_scanner_arg = 'private-code'
diff --git a/meson_options.txt b/meson_options.txt
index fa6a9809e11..9d52818c1d9 100644
--- a/meson_options.txt
+++ b/meson_options.txt
@@ -21,7 +21,7 @@
 option(
   'platforms',
   type : 'array',
-  value : ['auto'],
+  value : ['x11', 'wayland'],
   choices : [
     'auto', 'x11', 'wayland', 'haiku', 'android', 'windows',
   ],
@@ -37,14 +37,14 @@ option(
 option(
   'dri3',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'disabled', 'enabled'],
   description : 'enable support for dri3'
 )
 option(
   'dri-drivers',
   type : 'array',
-  value : ['auto'],
+  value : [],
   choices : ['auto', 'i915', 'i965', 'r100', 'r200', 'nouveau'],
   description : 'List of dri drivers to build. If this is set to auto all drivers applicable to the target OS/architecture will be built'
 )
@@ -63,7 +63,7 @@ option(
 option(
   'gallium-drivers',
   type : 'array',
-  value : ['auto'],
+  value : ['zink', 'swrast'],
   choices : [
     'auto', 'kmsro', 'radeonsi', 'r300', 'r600', 'nouveau', 'freedreno',
     'swrast', 'v3d', 'vc4', 'etnaviv', 'tegra', 'i915', 'svga', 'virgl',
@@ -80,7 +80,7 @@ option(
 option(
   'gallium-vdpau',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'enable gallium vdpau frontend.',
 )
@@ -93,7 +93,7 @@ option(
 option(
   'gallium-xvmc',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'enable gallium xvmc frontend.',
 )
@@ -106,7 +106,7 @@ option(
 option(
   'gallium-omx',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'disabled', 'bellagio', 'tizonia'],
   description : 'enable gallium omx frontend.',
 )
@@ -119,7 +119,7 @@ option(
 option(
   'gallium-va',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'enable gallium va frontend.',
 )
@@ -132,7 +132,7 @@ option(
 option(
   'gallium-xa',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'enable gallium xa frontend.',
 )
@@ -164,7 +164,7 @@ option(
 option(
   'opencl-native',
   type : 'boolean',
-  value : true,
+  value : false,
   description : 'build gallium "clover" OpenCL frontend with native LLVM codegen support.',
 )
 option(
@@ -183,7 +183,7 @@ option(
 option(
   'vulkan-drivers',
   type : 'array',
-  value : ['auto'],
+  value : [],
   choices : ['auto', 'amd', 'broadcom', 'freedreno', 'intel', 'swrast', 'virtio-experimental'],
   description : 'List of vulkan drivers to build. If this is set to auto all drivers applicable to the target OS/architecture will be built'
 )
@@ -196,7 +196,7 @@ option(
 option(
   'shader-cache',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build with on-disk shader cache support.',
 )
@@ -233,21 +233,21 @@ option(
 option(
   'shared-glapi',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Whether to build a shared or static glapi. Defaults to false on Windows, true elsewhere'
 )
 option(
   'gles1',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build support for OpenGL ES 1.x'
 )
 option(
   'gles2',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build support for OpenGL ES 2.x and 3.x'
 )
@@ -260,21 +260,21 @@ option(
 option(
   'gbm',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build support for gbm platform'
 )
 option(
   'glx',
   type : 'combo',
-  value : 'auto',
+  value : 'dri',
   choices : ['auto', 'disabled', 'dri', 'xlib', 'gallium-xlib'],
   description : 'Build support for GLX platform'
 )
 option(
   'egl',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build support for EGL platform'
 )
@@ -287,7 +287,7 @@ option(
 option(
   'microsoft-clc',
   type : 'feature',
-  value : 'auto',
+  value : 'disabled',
   description : 'Build support for the Microsoft CLC to DXIL compiler'
 )
 option(
@@ -311,14 +311,14 @@ option(
 option(
   'llvm',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build with LLVM support.'
 )
 option(
   'shared-llvm',
   type : 'combo',
-  value : 'auto',
+  value : 'enabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Whether to link LLVM shared or statically.'
 )
@@ -331,21 +331,21 @@ option(
 option(
   'valgrind',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Build with valgrind support'
 )
 option(
   'libunwind',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Use libunwind for stack-traces'
 )
 option(
   'lmsensors',
   type : 'combo',
-  value : 'auto',
+  value : 'disabled',
   choices : ['auto', 'true', 'false', 'enabled', 'disabled'],
   description : 'Enable HUD lmsensors support.'
 )
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index c89663575e7..a340d6d8bbd 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -4642,7 +4642,7 @@ bool nir_vectorize_tess_levels(nir_shader *shader);
 bool nir_lower_fragcolor(nir_shader *shader, unsigned max_cbufs);
 bool nir_lower_fragcoord_wtrans(nir_shader *shader);
 void nir_lower_viewport_transform(nir_shader *shader);
-bool nir_lower_uniforms_to_ubo(nir_shader *shader, bool dword_packed, bool load_vec4);
+bool nir_lower_uniforms_to_ubo(nir_shader *shader, int multiplier);
 
 bool nir_lower_is_helper_invocation(nir_shader *shader);
 
diff --git a/src/compiler/nir/nir_lower_uniforms_to_ubo.c b/src/compiler/nir/nir_lower_uniforms_to_ubo.c
index 0b37b705ef8..65107c01046 100644
--- a/src/compiler/nir/nir_lower_uniforms_to_ubo.c
+++ b/src/compiler/nir/nir_lower_uniforms_to_ubo.c
@@ -22,24 +22,27 @@
  */
 
 /*
- * Remap load_uniform intrinsics to nir_load_ubo or nir_load_ubo_vec4 accesses
- * of UBO binding point 0. Simultaneously, remap existing UBO accesses by
- * increasing their binding point by 1.
+ * Remap load_uniform intrinsics to UBO accesses of UBO binding point 0.
+ * Simultaneously, remap existing UBO accesses by increasing their binding
+ * point by 1.
  *
- * For PIPE_CAP_PACKED_UNIFORMS, dword_packed should be set to indicate that
- * nir_intrinsic_load_uniform is in increments of dwords instead of vec4s.
+ * Note that nir_intrinsic_load_uniform base/ranges can be set in different
+ * units, and the multiplier argument caters to supporting these different
+ * units.
  *
- * If load_vec4 is set, then nir_intrinsic_load_ubo_vec4 will be generated
- * instead of nir_intrinsic_load_ubo, saving addressing math for hardawre
- * needing aligned vec4 loads in increments of vec4s (such as TGSI CONST file
- * loads).
+ * For example:
+ * - st_glsl_to_nir for PIPE_CAP_PACKED_UNIFORMS uses dwords (4 bytes) so the
+ *   multiplier should be 4
+ * - st_glsl_to_nir for !PIPE_CAP_PACKED_UNIFORMS uses vec4s so the
+ *   multiplier should be 16
+ * - tgsi_to_nir uses vec4s, so the multiplier should be 16
  */
 
 #include "nir.h"
 #include "nir_builder.h"
 
 static bool
-lower_instr(nir_intrinsic_instr *instr, nir_builder *b, bool dword_packed, bool load_vec4)
+lower_instr(nir_intrinsic_instr *instr, nir_builder *b, int multiplier)
 {
    b->cursor = nir_before_instr(&instr->instr);
 
@@ -55,51 +58,43 @@ lower_instr(nir_intrinsic_instr *instr, nir_builder *b, bool dword_packed, bool
 
    if (instr->intrinsic == nir_intrinsic_load_uniform) {
       nir_ssa_def *ubo_idx = nir_imm_int(b, 0);
-      nir_ssa_def *uniform_offset = nir_ssa_for_src(b, instr->src[0], 1);
-
+      nir_ssa_def *ubo_offset =
+         nir_iadd(b, nir_imm_int(b, multiplier * nir_intrinsic_base(instr)),
+                  nir_imul(b, nir_imm_int(b, multiplier),
+                           nir_ssa_for_src(b, instr->src[0], 1)));
+
+      nir_intrinsic_instr *load =
+         nir_intrinsic_instr_create(b->shader, nir_intrinsic_load_ubo);
+      load->num_components = instr->num_components;
+      load->src[0] = nir_src_for_ssa(ubo_idx);
+      load->src[1] = nir_src_for_ssa(ubo_offset);
       assert(instr->dest.ssa.bit_size >= 8);
-      nir_ssa_def *load_result;
-      if (load_vec4) {
-         /* No asking us to generate load_vec4 when you've packed your uniforms
-          * as dwords instead of vec4s.
-          */
-         assert(!dword_packed);
-         load_result = nir_load_ubo_vec4(b, instr->num_components, instr->dest.ssa.bit_size,
-                                         ubo_idx,
-                                         nir_iadd_imm(b, uniform_offset, nir_intrinsic_base(instr)));
-      } else {
-         /* For PIPE_CAP_PACKED_UNIFORMS, the uniforms are packed with the
-          * base/offset in dword units instead of vec4 units.
-          */
-         int multiplier = dword_packed ? 4 : 16;
-         load_result = nir_load_ubo(b, instr->num_components, instr->dest.ssa.bit_size,
-                             ubo_idx,
-                             nir_iadd_imm(b, nir_imul_imm(b, uniform_offset, multiplier),
-                                          nir_intrinsic_base(instr) * multiplier));
-         nir_intrinsic_instr *load = nir_instr_as_intrinsic(load_result->parent_instr);
-
-         /* If it's const, set the alignment to our known constant offset.  If
-          * not, set it to a pessimistic value based on the multiplier (or the
-          * scalar size, for qword loads).
-          *
-          * We could potentially set up stricter alignments for indirects by
-          * knowing what features are enabled in the APIs (see comment in
-          * nir_lower_ubo_vec4.c)
-          */
-         if (nir_src_is_const(instr->src[0])) {
-            nir_intrinsic_set_align(load, NIR_ALIGN_MUL_MAX,
-                                    (nir_src_as_uint(instr->src[0]) +
-                                    nir_intrinsic_base(instr) * multiplier) %
-                                    NIR_ALIGN_MUL_MAX);
-         } else {
-            nir_intrinsic_set_align(load, MAX2(multiplier,
-                                             instr->dest.ssa.bit_size / 8), 0);
-         }
 
-         nir_intrinsic_set_range_base(load, nir_intrinsic_base(instr) * multiplier);
-         nir_intrinsic_set_range(load, nir_intrinsic_range(instr) * multiplier);
+      /* If it's const, set the alignment to our known constant offset.  If
+       * not, set it to a pessimistic value based on the multiplier (or the
+       * scalar size, for qword loads).
+       *
+       * We could potentially set up stricter alignments for indirects by
+       * knowing what features are enabled in the APIs (see comment in
+       * nir_lower_ubo_vec4.c)
+       */
+      if (nir_src_is_const(instr->src[0])) {
+         nir_intrinsic_set_align(load, NIR_ALIGN_MUL_MAX,
+                                 (nir_src_as_uint(instr->src[0]) +
+                                  nir_intrinsic_base(instr) * multiplier) %
+                                 NIR_ALIGN_MUL_MAX);
+      } else {
+         nir_intrinsic_set_align(load, MAX2(multiplier,
+                                            instr->dest.ssa.bit_size / 8), 0);
       }
-      nir_ssa_def_rewrite_uses(&instr->dest.ssa, load_result);
+      nir_ssa_dest_init(&load->instr, &load->dest,
+                        load->num_components, instr->dest.ssa.bit_size,
+                        instr->dest.ssa.name);
+      nir_builder_instr_insert(b, &load->instr);
+      nir_ssa_def_rewrite_uses(&instr->dest.ssa, &load->dest.ssa);
+
+      nir_intrinsic_set_range_base(load, nir_intrinsic_base(instr) * multiplier);
+      nir_intrinsic_set_range(load, nir_intrinsic_range(instr) * multiplier);
 
       nir_instr_remove(&instr->instr);
       return true;
@@ -109,7 +104,7 @@ lower_instr(nir_intrinsic_instr *instr, nir_builder *b, bool dword_packed, bool
 }
 
 bool
-nir_lower_uniforms_to_ubo(nir_shader *shader, bool dword_packed, bool load_vec4)
+nir_lower_uniforms_to_ubo(nir_shader *shader, int multiplier)
 {
    bool progress = false;
 
@@ -122,7 +117,7 @@ nir_lower_uniforms_to_ubo(nir_shader *shader, bool dword_packed, bool load_vec4)
                if (instr->type == nir_instr_type_intrinsic)
                   progress |= lower_instr(nir_instr_as_intrinsic(instr),
                                           &builder,
-                                          dword_packed, load_vec4);
+                                          multiplier);
             }
          }
 
diff --git a/src/egl/main/egldisplay.h b/src/egl/main/egldisplay.h
index 4d2afbc712e..2da7a33a97d 100644
--- a/src/egl/main/egldisplay.h
+++ b/src/egl/main/egldisplay.h
@@ -37,6 +37,7 @@
 #include "egltypedefs.h"
 #include "egldefines.h"
 #include "eglarray.h"
+#include <X11/Xlib.h>
 
 
 #ifdef __cplusplus
diff --git a/src/gallium/auxiliary/draw/draw_vs_llvm.c b/src/gallium/auxiliary/draw/draw_vs_llvm.c
index 00c63ed5f45..67ae6a16356 100644
--- a/src/gallium/auxiliary/draw/draw_vs_llvm.c
+++ b/src/gallium/auxiliary/draw/draw_vs_llvm.c
@@ -100,7 +100,7 @@ draw_create_vs_llvm(struct draw_context *draw,
       vs->base.state.ir.nir = state->ir.nir;
       nir_shader *nir = (nir_shader *)state->ir.nir;
       if (!nir->options->lower_uniforms_to_ubo)
-         NIR_PASS_V(state->ir.nir, nir_lower_uniforms_to_ubo, false, false);
+         NIR_PASS_V(state->ir.nir, nir_lower_uniforms_to_ubo, 16);
       nir_tgsi_scan_shader(state->ir.nir, &vs->base.info, true);
    } else {
       /* we make a private copy of the tokens */
diff --git a/src/gallium/auxiliary/meson.build b/src/gallium/auxiliary/meson.build
index a30e4418672..5357137a557 100644
--- a/src/gallium/auxiliary/meson.build
+++ b/src/gallium/auxiliary/meson.build
@@ -546,7 +546,7 @@ libgallium = static_library(
   gnu_symbol_visibility : 'hidden',
   dependencies : [
     dep_libdrm, dep_llvm, dep_dl, dep_m, dep_thread, dep_lmsensors, dep_ws2_32,
-    idep_nir, idep_nir_headers, idep_mesautil,
+    idep_nir, idep_nir_headers, idep_mesautil, dep_a, dep_l
   ],
   build_by_default : false
 )
diff --git a/src/gallium/auxiliary/nir/nir_to_tgsi.c b/src/gallium/auxiliary/nir/nir_to_tgsi.c
index 3c73d342ca1..5789a39d61b 100644
--- a/src/gallium/auxiliary/nir/nir_to_tgsi.c
+++ b/src/gallium/auxiliary/nir/nir_to_tgsi.c
@@ -2718,8 +2718,8 @@ nir_to_tgsi(struct nir_shader *s,
 
    if (!original_options->lower_uniforms_to_ubo) {
       NIR_PASS_V(s, nir_lower_uniforms_to_ubo,
-                 screen->get_param(screen, PIPE_CAP_PACKED_UNIFORMS),
-                 !native_integers);
+                 screen->get_param(screen, PIPE_CAP_PACKED_UNIFORMS) ?
+                 4 : 16);
    }
 
    /* Do lowering so we can directly translate f64/i64 NIR ALU ops to TGSI --
diff --git a/src/gallium/auxiliary/nir/tgsi_to_nir.c b/src/gallium/auxiliary/nir/tgsi_to_nir.c
index 18100e73f6e..044faac8569 100644
--- a/src/gallium/auxiliary/nir/tgsi_to_nir.c
+++ b/src/gallium/auxiliary/nir/tgsi_to_nir.c
@@ -2496,7 +2496,7 @@ ttn_finalize_nir(struct ttn_compile *c, struct pipe_screen *screen)
    }
 
    if (nir->options->lower_uniforms_to_ubo)
-      NIR_PASS_V(nir, nir_lower_uniforms_to_ubo, false, false);
+      NIR_PASS_V(nir, nir_lower_uniforms_to_ubo, 16);
 
    if (!c->cap_samplers_as_deref)
       NIR_PASS_V(nir, nir_lower_samplers);
diff --git a/src/gallium/drivers/zink/nir_lower_dynamic_bo_access.c b/src/gallium/drivers/zink/nir_lower_dynamic_bo_access.c
index 864030ad8d8..c5044301263 100644
--- a/src/gallium/drivers/zink/nir_lower_dynamic_bo_access.c
+++ b/src/gallium/drivers/zink/nir_lower_dynamic_bo_access.c
@@ -107,8 +107,12 @@ lower_dynamic_bo_access_instr(nir_intrinsic_instr *instr, nir_builder *b)
    bool ssbo_mode = instr->intrinsic != nir_intrinsic_load_ubo && instr->intrinsic != nir_intrinsic_load_ubo_vec4;
    unsigned first_idx = UINT_MAX, last_idx;
    if (ssbo_mode) {
-      nir_foreach_variable_with_modes(var, b->shader, nir_var_mem_ssbo)
-         first_idx = MIN2(first_idx, var->data.driver_location);
+      /* ssbo bindings don't always start at 0 */
+      nir_foreach_variable_with_modes(var, b->shader, nir_var_mem_ssbo) {
+         first_idx = var->data.binding;
+         break;
+      }
+      assert(first_idx != UINT_MAX);
       last_idx = first_idx + b->shader->info.num_ssbos;
    } else {
       /* skip 0 index if uniform_0 is one we created previously */
diff --git a/src/gallium/drivers/zink/nir_to_spirv/nir_to_spirv.c b/src/gallium/drivers/zink/nir_to_spirv/nir_to_spirv.c
index 6e267f5363f..99120b6b961 100644
--- a/src/gallium/drivers/zink/nir_to_spirv/nir_to_spirv.c
+++ b/src/gallium/drivers/zink/nir_to_spirv/nir_to_spirv.c
@@ -46,9 +46,12 @@ struct ntv_context {
    const struct zink_so_info *so_info;
 
    SpvId ubos[128];
+   size_t num_ubos;
 
    SpvId ssbos[PIPE_MAX_SHADER_BUFFERS];
    nir_variable *ssbo_vars[PIPE_MAX_SHADER_BUFFERS];
+   uint32_t ssbo_mask;
+   uint32_t num_ssbos;
    SpvId image_types[PIPE_MAX_SAMPLERS];
    SpvId images[PIPE_MAX_SAMPLERS];
    SpvId sampler_types[PIPE_MAX_SAMPLERS];
@@ -864,8 +867,8 @@ get_bo_array_type(struct ntv_context *ctx, struct nir_variable *var)
       array_type = spirv_builder_type_runtime_array(&ctx->builder, uint_type);
       spirv_builder_emit_array_stride(&ctx->builder, array_type, 4);
    } else {
-      uint32_t array_size = glsl_get_length(glsl_get_struct_field(var->interface_type, 0));
-      array_type = get_sized_uint_array_type(ctx, array_size);
+      uint32_t array_size = glsl_count_attribute_slots(var->interface_type, false);
+      array_type = get_sized_uint_array_type(ctx, array_size * 4);
    }
    return array_type;
 }
@@ -879,12 +882,14 @@ get_bo_struct_type(struct ntv_context *ctx, struct nir_variable *var)
    // wrap UBO-array in a struct
    SpvId runtime_array = 0;
    if (ssbo) {
-       const struct glsl_type *last_member = glsl_get_struct_field(var->interface_type, glsl_get_length(var->interface_type) - 1);
-       if (glsl_type_is_unsized_array(last_member)) {
-          bool is_64bit = glsl_type_is_64bit(glsl_without_array(last_member));
-          runtime_array = spirv_builder_type_runtime_array(&ctx->builder, get_uvec_type(ctx, is_64bit ? 64 : 32, 1));
-          spirv_builder_emit_array_stride(&ctx->builder, runtime_array, glsl_get_explicit_stride(last_member));
-       }
+      if (glsl_type_is_interface(var->interface_type) && !glsl_type_is_unsized_array(var->type)) {
+          const struct glsl_type *last_member = glsl_get_struct_field(var->interface_type, glsl_get_length(var->interface_type) - 1);
+          if (glsl_type_is_unsized_array(last_member)) {
+             bool is_64bit = glsl_type_is_64bit(glsl_without_array(last_member));
+             runtime_array = spirv_builder_type_runtime_array(&ctx->builder, get_uvec_type(ctx, is_64bit ? 64 : 32, 1));
+             spirv_builder_emit_array_stride(&ctx->builder, runtime_array, glsl_get_explicit_stride(last_member));
+          }
+      }
    }
    SpvId types[] = {array_type, runtime_array};
    SpvId struct_type = spirv_builder_type_struct(&ctx->builder, types, 1 + !!runtime_array);
@@ -1846,6 +1851,7 @@ emit_load_bo(struct ntv_context *ctx, nir_intrinsic_instr *intr)
    assert(const_block_index); // no dynamic indexing for now
 
    SpvId bo = ssbo ? ctx->ssbos[const_block_index->u32] : ctx->ubos[const_block_index->u32];
+
    unsigned bit_size = nir_dest_bit_size(intr->dest);
    SpvId uint_type = get_uvec_type(ctx, 32, 1);
    SpvId one = emit_uint_const(ctx, 32, 1);
diff --git a/src/gallium/drivers/zink/zink_compiler.c b/src/gallium/drivers/zink/zink_compiler.c
index 6e480ec48af..b7f1a6505c1 100644
--- a/src/gallium/drivers/zink/zink_compiler.c
+++ b/src/gallium/drivers/zink/zink_compiler.c
@@ -699,112 +699,6 @@ bool nir_lower_dynamic_bo_access(nir_shader *shader);
 /* gl_nir_lower_buffers makes variables unusable for all UBO/SSBO access
  * so instead we delete all those broken variables and just make new ones
  */
-static bool
-unbreak_bos(nir_shader *shader)
-{
-   uint32_t ssbo_used = 0;
-   uint32_t ubo_used = 0;
-   uint64_t max_ssbo_size = 0;
-   uint64_t max_ubo_size = 0;
-   bool ssbo_sizes[PIPE_MAX_SHADER_BUFFERS] = {false};
-
-   if (!shader->info.num_ssbos && !shader->info.num_ubos && !shader->num_uniforms)
-      return false;
-   nir_function_impl *impl = nir_shader_get_entrypoint(shader);
-   nir_foreach_block(block, impl) {
-      nir_foreach_instr(instr, block) {
-         if (instr->type != nir_instr_type_intrinsic)
-            continue;
-
-         nir_intrinsic_instr *intrin = nir_instr_as_intrinsic(instr);
-         switch (intrin->intrinsic) {
-         case nir_intrinsic_store_ssbo:
-            ssbo_used |= BITFIELD_BIT(nir_src_as_uint(intrin->src[1]));
-            break;
-
-         case nir_intrinsic_get_ssbo_size: {
-            uint32_t slot = nir_src_as_uint(intrin->src[0]);
-            ssbo_used |= BITFIELD_BIT(slot);
-            ssbo_sizes[slot] = true;
-            break;
-         }
-         case nir_intrinsic_ssbo_atomic_add:
-         case nir_intrinsic_ssbo_atomic_imin:
-         case nir_intrinsic_ssbo_atomic_umin:
-         case nir_intrinsic_ssbo_atomic_imax:
-         case nir_intrinsic_ssbo_atomic_umax:
-         case nir_intrinsic_ssbo_atomic_and:
-         case nir_intrinsic_ssbo_atomic_or:
-         case nir_intrinsic_ssbo_atomic_xor:
-         case nir_intrinsic_ssbo_atomic_exchange:
-         case nir_intrinsic_ssbo_atomic_comp_swap:
-         case nir_intrinsic_ssbo_atomic_fmin:
-         case nir_intrinsic_ssbo_atomic_fmax:
-         case nir_intrinsic_ssbo_atomic_fcomp_swap:
-         case nir_intrinsic_load_ssbo:
-            ssbo_used |= BITFIELD_BIT(nir_src_as_uint(intrin->src[0]));
-            break;
-         case nir_intrinsic_load_ubo:
-         case nir_intrinsic_load_ubo_vec4:
-            ubo_used |= BITFIELD_BIT(nir_src_as_uint(intrin->src[0]));
-            break;
-         default:
-            break;
-         }
-      }
-   }
-
-   nir_foreach_variable_with_modes(var, shader, nir_var_mem_ssbo | nir_var_mem_ubo) {
-      const struct glsl_type *type = glsl_without_array(var->type);
-      if (type_is_counter(type))
-         continue;
-      unsigned size = glsl_count_attribute_slots(type, false);
-      if (var->data.mode == nir_var_mem_ubo)
-         max_ubo_size = MAX2(max_ubo_size, size);
-      else
-         max_ssbo_size = MAX2(max_ssbo_size, size);
-      var->data.mode = nir_var_shader_temp;
-   }
-   nir_fixup_deref_modes(shader);
-   NIR_PASS_V(shader, nir_remove_dead_variables, nir_var_shader_temp, NULL);
-   optimize_nir(shader);
-
-   if (!ssbo_used && !ubo_used)
-      return false;
-
-   struct glsl_struct_field *fields = rzalloc_array(shader, struct glsl_struct_field, 2);
-   fields[0].name = ralloc_strdup(shader, "base");
-   fields[1].name = ralloc_strdup(shader, "unsized");
-   if (ubo_used) {
-      const struct glsl_type *ubo_type = glsl_array_type(glsl_uint_type(), max_ubo_size * 4, 4);
-      fields[0].type = ubo_type;
-      u_foreach_bit(slot, ubo_used) {
-         char buf[64];
-         snprintf(buf, sizeof(buf), "ubo_slot_%u", slot);
-         nir_variable *var = nir_variable_create(shader, nir_var_mem_ubo, glsl_struct_type(fields, 1, "struct", false), buf);
-         var->interface_type = var->type;
-         var->data.driver_location = slot;
-      }
-   }
-   if (ssbo_used) {
-      const struct glsl_type *ssbo_type = glsl_array_type(glsl_uint_type(), max_ssbo_size * 4, 4);
-      const struct glsl_type *unsized = glsl_array_type(glsl_uint_type(), 0, 4);
-      fields[0].type = ssbo_type;
-      u_foreach_bit(slot, ssbo_used) {
-         char buf[64];
-         snprintf(buf, sizeof(buf), "ssbo_slot_%u", slot);
-         if (ssbo_sizes[slot])
-            fields[1].type = unsized;
-         else
-            fields[1].type = NULL;
-         nir_variable *var = nir_variable_create(shader, nir_var_mem_ssbo,
-                                                 glsl_struct_type(fields, 1 + !!ssbo_sizes[slot], "struct", false), buf);
-         var->interface_type = var->type;
-         var->data.driver_location = slot;
-      }
-   }
-   return true;
-}
 
 static uint32_t
 zink_binding(gl_shader_stage stage, VkDescriptorType type, int index)
@@ -848,24 +742,27 @@ zink_shader_create(struct zink_screen *screen, struct nir_shader *nir,
    ret->shader_id = p_atomic_inc_return(&screen->shader_id);
    ret->programs = _mesa_pointer_set_create(NULL);
 
-   nir_variable_mode indirect_derefs_modes = nir_var_function_temp;
-   if (nir->info.stage == MESA_SHADER_TESS_CTRL ||
-       nir->info.stage == MESA_SHADER_TESS_EVAL)
-      indirect_derefs_modes |= nir_var_shader_in | nir_var_shader_out;
-
-   NIR_PASS_V(nir, nir_lower_indirect_derefs, indirect_derefs_modes,
-              UINT32_MAX);
+   if (!screen->info.feats.features.shaderImageGatherExtended) {
+      nir_lower_tex_options tex_opts = {};
+      tex_opts.lower_tg4_offsets = true;
+      NIR_PASS_V(nir, nir_lower_tex, &tex_opts);
+   }
 
    if (nir->info.stage == MESA_SHADER_VERTEX)
       create_vs_pushconst(nir);
    else if (nir->info.stage == MESA_SHADER_TESS_CTRL ||
-            nir->info.stage == MESA_SHADER_TESS_EVAL)
+            nir->info.stage == MESA_SHADER_TESS_EVAL) {
+      NIR_PASS_V(nir, nir_lower_indirect_derefs, nir_var_shader_in |
+                 nir_var_shader_out, UINT32_MAX);
       NIR_PASS_V(nir, nir_lower_io_arrays_to_elements_no_indirects, false);
-   else if (nir->info.stage == MESA_SHADER_KERNEL)
+   } else if (nir->info.stage == MESA_SHADER_KERNEL)
       create_cs_pushconst(nir);
 
+   NIR_PASS_V(nir, nir_lower_uniforms_to_ubo, 16);
    if (nir->info.stage < MESA_SHADER_FRAGMENT)
       have_psiz = check_psiz(nir);
+   if (nir->info.stage == MESA_SHADER_GEOMETRY)
+      NIR_PASS_V(nir, nir_lower_gs_intrinsics, nir_lower_gs_intrinsics_per_stream);
    NIR_PASS_V(nir, lower_basevertex);
    NIR_PASS_V(nir, lower_work_dim);
    NIR_PASS_V(nir, nir_lower_regs_to_ssa);
@@ -876,7 +773,8 @@ zink_shader_create(struct zink_screen *screen, struct nir_shader *nir,
    NIR_PASS_V(nir, nir_lower_fragcolor,
          nir->info.fs.color_is_dual_source ? 1 : 8);
    NIR_PASS_V(nir, lower_64bit_vertex_attribs);
-   NIR_PASS_V(nir, unbreak_bos);
+   if (nir->info.num_ubos || nir->info.num_ssbos)
+     NIR_PASS_V(nir, nir_lower_dynamic_bo_access);
 
    if (zink_debug & ZINK_DEBUG_NIR) {
       fprintf(stderr, "NIR shader:\n---8<---\n");
@@ -884,6 +782,14 @@ zink_shader_create(struct zink_screen *screen, struct nir_shader *nir,
       fprintf(stderr, "---8<---\n");
    }
 
+   /* UBO buffers are zero-indexed, but buffer 0 is always the one created by nir_lower_uniforms_to_ubo,
+    * which means there is no buffer 0 if there are no uniforms
+    */
+   int ubo_index = !nir->num_uniforms;
+   /* need to set up var->data.binding for UBOs, which means we need to start at
+    * the "first" UBO, which is at the end of the list
+    */
+   int ssbo_array_index = 0;
    foreach_list_typed_reverse(nir_variable, var, node, &nir->variables) {
       if (_nir_shader_variable_has_mode(var, nir_var_uniform |
                                         nir_var_mem_ubo |
@@ -970,28 +876,6 @@ zink_shader_create(struct zink_screen *screen, struct nir_shader *nir,
    return ret;
 }
 
-void
-zink_shader_finalize(struct pipe_screen *pscreen, void *nirptr, bool optimize)
-{
-   struct zink_screen *screen = zink_screen(pscreen);
-   nir_shader *nir = nirptr;
-
-   if (!screen->info.feats.features.shaderImageGatherExtended) {
-      nir_lower_tex_options tex_opts = {};
-      tex_opts.lower_tg4_offsets = true;
-      NIR_PASS_V(nir, nir_lower_tex, &tex_opts);
-   }
-   NIR_PASS_V(nir, nir_lower_uniforms_to_ubo, true, false);
-   if (nir->info.stage == MESA_SHADER_GEOMETRY)
-      NIR_PASS_V(nir, nir_lower_gs_intrinsics, nir_lower_gs_intrinsics_per_stream);
-   optimize_nir(nir);
-   if (nir->info.num_ubos || nir->info.num_ssbos)
-      NIR_PASS_V(nir, nir_lower_dynamic_bo_access);
-   nir_shader_gather_info(nir, nir_shader_get_entrypoint(nir));
-   if (screen->driconf.inline_uniforms)
-      nir_find_inlinable_uniforms(nir);
-}
-
 void
 zink_shader_free(struct zink_context *ctx, struct zink_shader *shader)
 {
diff --git a/src/gallium/drivers/zink/zink_compiler.h b/src/gallium/drivers/zink/zink_compiler.h
index 06366c6bd10..feaebffdea8 100644
--- a/src/gallium/drivers/zink/zink_compiler.h
+++ b/src/gallium/drivers/zink/zink_compiler.h
@@ -100,9 +100,6 @@ struct zink_shader *
 zink_shader_create(struct zink_screen *screen, struct nir_shader *nir,
                  const struct pipe_stream_output_info *so_info);
 
-void
-zink_shader_finalize(struct pipe_screen *pscreen, void *nirptr, bool optimize);
-
 void
 zink_shader_free(struct zink_context *ctx, struct zink_shader *shader);
 
diff --git a/src/gallium/drivers/zink/zink_context.c b/src/gallium/drivers/zink/zink_context.c
index 3888cb3a9a6..fcd70bfc9f8 100644
--- a/src/gallium/drivers/zink/zink_context.c
+++ b/src/gallium/drivers/zink/zink_context.c
@@ -809,17 +809,6 @@ zink_set_polygon_stipple(struct pipe_context *pctx,
 {
 }
 
-static inline void
-update_res_bind_count(struct zink_context *ctx, struct zink_resource *res, bool is_compute, bool decrement)
-{
-   if (decrement) {
-      assert(res->bind_count[is_compute]);
-      if (!--res->bind_count[is_compute])
-         _mesa_set_remove_key(ctx->need_barriers[is_compute], res);
-   } else
-      res->bind_count[is_compute]++;
-}
-
 static void
 update_existing_vbo(struct zink_context *ctx, unsigned slot)
 {
@@ -827,7 +816,9 @@ update_existing_vbo(struct zink_context *ctx, unsigned slot)
       return;
    struct zink_resource *res = zink_resource(ctx->vertex_buffers[slot].buffer.resource);
    res->vbo_bind_count--;
-   update_res_bind_count(ctx, res, false, true);
+   res->bind_count[0]--;
+   if (!res->bind_count[0])
+      _mesa_set_remove_key(ctx->need_barriers[0], res);
 }
 
 static void
@@ -840,48 +831,28 @@ zink_set_vertex_buffers(struct pipe_context *pctx,
 {
    struct zink_context *ctx = zink_context(pctx);
 
-   uint32_t enabled_buffers = ctx->gfx_pipeline_state.vertex_buffers_enabled_mask;
-   enabled_buffers |= u_bit_consecutive(start_slot, num_buffers);
-   enabled_buffers &= ~u_bit_consecutive(start_slot + num_buffers, unbind_num_trailing_slots);
-
    if (buffers) {
-      if (!zink_screen(pctx->screen)->info.have_EXT_extended_dynamic_state)
-         ctx->gfx_pipeline_state.vertex_state_dirty = true;
-      for (unsigned i = 0; i < num_buffers; ++i) {
+      for (int i = 0; i < num_buffers; ++i) {
          const struct pipe_vertex_buffer *vb = buffers + i;
-         struct pipe_vertex_buffer *ctx_vb = &ctx->vertex_buffers[start_slot + i];
          update_existing_vbo(ctx, start_slot + i);
-         if (!take_ownership)
-            pipe_resource_reference(&ctx_vb->buffer.resource, vb->buffer.resource);
-         else {
-            pipe_resource_reference(&ctx_vb->buffer.resource, NULL);
-            ctx_vb->buffer.resource = vb->buffer.resource;
-         }
          if (vb->buffer.resource) {
             struct zink_resource *res = zink_resource(vb->buffer.resource);
             res->vbo_bind_count++;
-            update_res_bind_count(ctx, res, false, false);
-            ctx_vb->stride = vb->stride;
-            ctx_vb->buffer_offset = vb->buffer_offset;
-            zink_batch_reference_resource_rw(&ctx->batch, res, false);
+            res->bind_count[0]++;
             zink_resource_buffer_barrier(ctx, NULL, res, VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT,
                                          VK_PIPELINE_STAGE_VERTEX_INPUT_BIT);
          }
       }
-   } else {
-      if (!zink_screen(pctx->screen)->info.have_EXT_extended_dynamic_state)
-         ctx->gfx_pipeline_state.vertex_state_dirty = true;
-      for (unsigned i = 0; i < num_buffers; ++i) {
-         update_existing_vbo(ctx, start_slot + i);
-         pipe_resource_reference(&ctx->vertex_buffers[start_slot + i].buffer.resource, NULL);
+   } else if (ctx->gfx_pipeline_state.vertex_buffers_enabled_mask) {
+      unsigned vertex_buffers_enabled_mask = ctx->gfx_pipeline_state.vertex_buffers_enabled_mask;
+      while (vertex_buffers_enabled_mask) {
+         unsigned slot = u_bit_scan(&vertex_buffers_enabled_mask);
+         update_existing_vbo(ctx, slot);
       }
    }
-   for (unsigned i = 0; i < unbind_num_trailing_slots; i++) {
-      update_existing_vbo(ctx, start_slot + i);
-      pipe_resource_reference(&ctx->vertex_buffers[start_slot + i].buffer.resource, NULL);
-   }
-   ctx->gfx_pipeline_state.vertex_buffers_enabled_mask = enabled_buffers;
-   ctx->vertex_buffers_dirty = num_buffers > 0;
+   util_set_vertex_buffers_mask(ctx->vertex_buffers, &ctx->gfx_pipeline_state.vertex_buffers_enabled_mask,
+                                buffers, start_slot, num_buffers,
+                                unbind_num_trailing_slots, take_ownership);
 }
 
 static void
@@ -901,7 +872,6 @@ zink_set_viewport_states(struct pipe_context *pctx,
          ctx->gfx_pipeline_state.dirty = true;
       ctx->gfx_pipeline_state.num_viewports = ctx->vp_state.num_viewports;
    }
-   ctx->vp_state_changed = true;
 }
 
 static void
@@ -913,7 +883,6 @@ zink_set_scissor_states(struct pipe_context *pctx,
 
    for (unsigned i = 0; i < num_scissors; i++)
       ctx->vp_state.scissor_states[start_slot + i] = states[i];
-   ctx->scissor_changed = true;
 }
 
 static void
@@ -928,15 +897,6 @@ zink_set_inlinable_constants(struct pipe_context *pctx,
    ctx->inlinable_uniforms_valid_mask |= 1 << shader;
 }
 
-static inline void
-unbind_ubo(struct zink_context *ctx, struct zink_resource *res, bool is_compute)
-{
-   if (!res)
-      return;
-   res->ubo_bind_count[is_compute]--;
-   update_res_bind_count(ctx, res, is_compute, true);
-}
-
 static void
 zink_set_constant_buffer(struct pipe_context *pctx,
                          enum pipe_shader_type shader, uint index,
@@ -947,6 +907,12 @@ zink_set_constant_buffer(struct pipe_context *pctx,
    bool update = false;
 
    struct zink_resource *res = zink_resource(ctx->ubos[shader][index].buffer);
+   if (res) {
+      res->ubo_bind_count[shader == PIPE_SHADER_COMPUTE]--;
+      res->bind_count[shader == PIPE_SHADER_COMPUTE]--;
+      if (!res->bind_count[shader == PIPE_SHADER_COMPUTE])
+         _mesa_set_remove_key(ctx->need_barriers[shader == PIPE_SHADER_COMPUTE], res);
+   }
    if (cb) {
       struct pipe_resource *buffer = cb->buffer;
       unsigned offset = cb->buffer_offset;
@@ -958,13 +924,10 @@ zink_set_constant_buffer(struct pipe_context *pctx,
       }
       struct zink_resource *new_res = zink_resource(buffer);
       if (new_res) {
-         if (new_res != res) {
-            unbind_ubo(ctx, res, shader == PIPE_SHADER_COMPUTE);
-            new_res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_UBO);
-            new_res->bind_stages |= 1 << shader;
-            new_res->ubo_bind_count[shader == PIPE_SHADER_COMPUTE]++;
-            update_res_bind_count(ctx, new_res, shader == PIPE_SHADER_COMPUTE, false);
-         }
+         new_res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_UBO);
+         new_res->bind_stages |= 1 << shader;
+         new_res->ubo_bind_count[shader == PIPE_SHADER_COMPUTE]++;
+         new_res->bind_count[shader == PIPE_SHADER_COMPUTE]++;
          if (!ctx->descriptor_refs_dirty[shader == PIPE_SHADER_COMPUTE])
             zink_batch_reference_resource_rw(&ctx->batch, new_res, false);
          zink_resource_buffer_barrier(ctx, NULL, new_res, VK_ACCESS_UNIFORM_READ_BIT,
@@ -990,8 +953,6 @@ zink_set_constant_buffer(struct pipe_context *pctx,
       if (index + 1 >= ctx->di.num_ubos[shader])
          ctx->di.num_ubos[shader] = index + 1;
    } else {
-      if (res)
-         unbind_ubo(ctx, res, shader == PIPE_SHADER_COMPUTE);
       update = !!ctx->ubos[shader][index].buffer;
 
       pipe_resource_reference(&ctx->ubos[shader][index].buffer, NULL);
@@ -1011,16 +972,6 @@ zink_set_constant_buffer(struct pipe_context *pctx,
       zink_screen(pctx->screen)->context_invalidate_descriptor_state(ctx, shader, ZINK_DESCRIPTOR_TYPE_UBO, index, 1);
 }
 
-static inline void
-unbind_ssbo(struct zink_context *ctx, struct zink_resource *res, bool is_compute, bool writable)
-{
-   if (!res)
-      return;
-   update_res_bind_count(ctx, res, is_compute, true);
-   if (writable)
-      res->write_bind_count[is_compute]--;
-}
-
 static void
 zink_set_shader_buffers(struct pipe_context *pctx,
                         enum pipe_shader_type p_stage,
@@ -1039,36 +990,38 @@ zink_set_shader_buffers(struct pipe_context *pctx,
 
    for (unsigned i = 0; i < count; i++) {
       struct pipe_shader_buffer *ssbo = &ctx->ssbos[p_stage][start_slot + i];
-      struct zink_resource *res = ssbo->buffer ? zink_resource(ssbo->buffer) : NULL;
-      bool was_writable = old_writable_mask & BITFIELD64_BIT(start_slot + i);
+      if (ssbo->buffer) {
+         struct zink_resource *res = zink_resource(ssbo->buffer);
+         res->bind_count[p_stage == PIPE_SHADER_COMPUTE]--;
+         if (!res->bind_count[p_stage == PIPE_SHADER_COMPUTE])
+            _mesa_set_remove_key(ctx->need_barriers[p_stage == PIPE_SHADER_COMPUTE], res);
+         if (old_writable_mask & BITFIELD64_BIT(start_slot + i))
+            res->write_bind_count[p_stage == PIPE_SHADER_COMPUTE]--;
+      }
       if (buffers && buffers[i].buffer) {
-         struct zink_resource *new_res = zink_resource(buffers[i].buffer);
-         if (new_res != res) {
-            unbind_ssbo(ctx, res, p_stage == PIPE_SHADER_COMPUTE, was_writable);
-            new_res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_SSBO);
-            new_res->bind_stages |= 1 << p_stage;
-            update_res_bind_count(ctx, new_res, p_stage == PIPE_SHADER_COMPUTE, false);
-         }
+         struct zink_resource *res = zink_resource(buffers[i].buffer);
+         res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_SSBO);
+         res->bind_stages |= 1 << p_stage;
+         res->bind_count[p_stage == PIPE_SHADER_COMPUTE]++;
          VkAccessFlags access = VK_ACCESS_SHADER_READ_BIT;
          if (ctx->writable_ssbos[p_stage] & BITFIELD64_BIT(start_slot + i)) {
-            new_res->write_bind_count[p_stage == PIPE_SHADER_COMPUTE]++;
+            res->write_bind_count[p_stage == PIPE_SHADER_COMPUTE]++;
             access |= VK_ACCESS_SHADER_WRITE_BIT;
          }
-         pipe_resource_reference(&ssbo->buffer, &new_res->base.b);
          if (!ctx->descriptor_refs_dirty[p_stage == PIPE_SHADER_COMPUTE])
-            zink_batch_reference_resource_rw(&ctx->batch, new_res, access & VK_ACCESS_SHADER_WRITE_BIT);
+            zink_batch_reference_resource_rw(&ctx->batch, res, access & VK_ACCESS_SHADER_WRITE_BIT);
+         pipe_resource_reference(&ssbo->buffer, &res->base.b);
          ssbo->buffer_offset = buffers[i].buffer_offset;
-         ssbo->buffer_size = MIN2(buffers[i].buffer_size, new_res->obj->size - ssbo->buffer_offset);
-         util_range_add(&new_res->base.b, &new_res->valid_buffer_range, ssbo->buffer_offset,
+         ssbo->buffer_size = MIN2(buffers[i].buffer_size, res->obj->size - ssbo->buffer_offset);
+         util_range_add(&res->base.b, &res->valid_buffer_range, ssbo->buffer_offset,
                         ssbo->buffer_offset + ssbo->buffer_size);
-         zink_resource_buffer_barrier(ctx, NULL, new_res, access,
+         zink_resource_buffer_barrier(ctx, NULL, res, access,
                                       zink_pipeline_flags_from_stage(zink_shader_stage(p_stage)));
          update = true;
          max_slot = MAX2(max_slot, start_slot + i);
       } else {
-         update = !!res;
-         if (res)
-            unbind_ssbo(ctx, res, p_stage == PIPE_SHADER_COMPUTE, was_writable);
+         update |= !!ssbo->buffer;
+
          pipe_resource_reference(&ssbo->buffer, NULL);
          ssbo->buffer_offset = 0;
          ssbo->buffer_size = 0;
@@ -1081,16 +1034,6 @@ zink_set_shader_buffers(struct pipe_context *pctx,
       zink_screen(pctx->screen)->context_invalidate_descriptor_state(ctx, p_stage, ZINK_DESCRIPTOR_TYPE_SSBO, start_slot, count);
 }
 
-static inline void
-unbind_shader_image_counts(struct zink_context *ctx, struct zink_resource *res, bool is_compute, bool writable)
-{
-   update_res_bind_count(ctx, res, is_compute, true);
-   if (writable)
-      res->write_bind_count[is_compute]--;
-   if (!res->obj->is_buffer)
-      res->image_bind_count[is_compute]--;
-}
-
 static void
 update_binds_for_samplerviews(struct zink_context *ctx, struct zink_resource *res, bool is_compute)
 {
@@ -1118,7 +1061,6 @@ unbind_shader_image(struct zink_context *ctx, enum pipe_shader_type stage, unsig
       return;
 
    struct zink_resource *res = zink_resource(image_view->base.resource);
-   unbind_shader_image_counts(ctx, res, stage == PIPE_SHADER_COMPUTE, image_view->base.access & PIPE_IMAGE_ACCESS_WRITE);
    /* if this was the last image bind, the sampler bind layouts must be updated */
    if (!res->image_bind_count[is_compute] && res->bind_count[is_compute])
       update_binds_for_samplerviews(ctx, res, is_compute);
@@ -1127,6 +1069,7 @@ unbind_shader_image(struct zink_context *ctx, enum pipe_shader_type stage, unsig
    if (image_view->base.resource->target == PIPE_BUFFER)
       zink_buffer_view_reference(zink_screen(ctx->base.screen), &image_view->buffer_view, NULL);
    else {
+      struct zink_resource *res = zink_resource(image_view->base.resource);
       if (res->bind_count[is_compute] &&
           !res->image_bind_count[is_compute]) {
          for (unsigned i = 0; i < PIPE_SHADER_TYPES; i++) {
@@ -1156,21 +1099,26 @@ zink_set_shader_images(struct pipe_context *pctx,
    bool update = false;
    for (unsigned i = 0; i < count; i++) {
       struct zink_image_view *image_view = &ctx->image_views[p_stage][start_slot + i];
+      if (image_view->base.resource) {
+         struct zink_resource *res = zink_resource(image_view->base.resource);
+         res->bind_count[p_stage == PIPE_SHADER_COMPUTE]--;
+         if (!res->bind_count[p_stage == PIPE_SHADER_COMPUTE])
+            _mesa_set_remove_key(ctx->need_barriers[p_stage == PIPE_SHADER_COMPUTE], res);
+         if (image_view->base.access & PIPE_IMAGE_ACCESS_WRITE)
+            res->write_bind_count[p_stage == PIPE_SHADER_COMPUTE]--;
+         if (image_view->base.resource->target != PIPE_BUFFER)
+            res->image_bind_count[p_stage == PIPE_SHADER_COMPUTE]--;
+      }
       if (images && images[i].resource) {
          util_dynarray_init(&image_view->desc_set_refs.refs, NULL);
          struct zink_resource *res = zink_resource(images[i].resource);
-         struct zink_resource *old_res = zink_resource(image_view->base.resource);
          if (!zink_resource_object_init_storage(ctx, res)) {
             debug_printf("couldn't create storage image!");
             continue;
          }
-         if (res != old_res) {
-            if (old_res)
-               unbind_shader_image_counts(ctx, old_res, p_stage == PIPE_SHADER_COMPUTE, image_view->base.access & PIPE_IMAGE_ACCESS_WRITE);
-            res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_IMAGE);
-            res->bind_stages |= 1 << p_stage;
-            update_res_bind_count(ctx, res, p_stage == PIPE_SHADER_COMPUTE, false);
-         }
+         res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_IMAGE);
+         res->bind_stages |= 1 << p_stage;
+         res->bind_count[p_stage == PIPE_SHADER_COMPUTE]++;
          util_copy_image_view(&image_view->base, images + i);
          VkAccessFlags access = 0;
          if (image_view->base.access & PIPE_IMAGE_ACCESS_WRITE) {
@@ -1246,7 +1194,9 @@ unbind_samplerview(struct zink_context *ctx, enum pipe_shader_type stage, unsign
    if (!sv || !sv->base.texture)
       return;
    struct zink_resource *res = zink_resource(sv->base.texture);
-   update_res_bind_count(ctx, res, stage == PIPE_SHADER_COMPUTE, true);
+   res->bind_count[stage == PIPE_SHADER_COMPUTE]--;
+   if (!res->bind_count[stage == PIPE_SHADER_COMPUTE])
+      _mesa_set_remove_key(ctx->need_barriers[stage == PIPE_SHADER_COMPUTE], res);
    if (!res->obj->is_buffer)
       res->sampler_binds[stage] &= ~BITFIELD_BIT(slot);
 }
@@ -1267,6 +1217,7 @@ zink_set_sampler_views(struct pipe_context *pctx,
       struct pipe_sampler_view *pview = views ? views[i] : NULL;
       struct zink_sampler_view *a = zink_sampler_view(ctx->sampler_views[shader_type][start_slot + i]);
       struct zink_sampler_view *b = zink_sampler_view(pview);
+      unbind_samplerview(ctx, shader_type, start_slot + i);
       if (b && b->base.texture) {
          struct zink_resource *res = zink_resource(b->base.texture);
          if (res->base.b.target == PIPE_BUFFER) {
@@ -1308,21 +1259,15 @@ zink_set_sampler_views(struct pipe_context *pctx,
              if (!a)
                 update = true;
          }
-         if (!a || zink_resource(a->base.texture) != res) {
-            if (a)
-               unbind_samplerview(ctx, shader_type, start_slot + i);
-            update_res_bind_count(ctx, res, shader_type == PIPE_SHADER_COMPUTE, false);
-            res->bind_history |= BITFIELD64_BIT(ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW);
-            res->bind_stages |= 1 << shader_type;
-         }
          if (!ctx->descriptor_refs_dirty[shader_type == PIPE_SHADER_COMPUTE]) {
             zink_batch_reference_resource_rw(&ctx->batch, res, false);
             zink_batch_reference_sampler_view(&ctx->batch, b);
          }
-      } else if (a) {
-         unbind_samplerview(ctx, shader_type, start_slot + i);
+         res->bind_count[shader_type == PIPE_SHADER_COMPUTE]++;
+         res->bind_history |= BITFIELD_BIT(ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW);
+         res->bind_stages |= 1 << shader_type;
+      } else if (a)
          update = true;
-      }
       pipe_sampler_view_reference(&ctx->sampler_views[shader_type][start_slot + i], pview);
       update_descriptor_state(ctx, shader_type, ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW, start_slot + i);
    }
@@ -1753,10 +1698,6 @@ flush_batch(struct zink_context *ctx, bool sync)
       if (zink_screen(ctx->base.screen)->info.have_EXT_transform_feedback && ctx->num_so_targets)
          ctx->dirty_so_targets = true;
       ctx->descriptor_refs_dirty[0] = ctx->descriptor_refs_dirty[1] = true;
-      ctx->pipeline_changed[0] = ctx->pipeline_changed[1] = true;
-      ctx->vertex_buffers_dirty = true;
-      ctx->vp_state_changed = true;
-      ctx->scissor_changed = true;
    }
 }
 
@@ -1834,12 +1775,7 @@ zink_set_framebuffer_state(struct pipe_context *pctx,
    ctx->rp_changed |= ctx->fb_state.nr_cbufs != state->nr_cbufs;
    ctx->rp_changed |= !!ctx->fb_state.zsbuf != !!state->zsbuf;
 
-   unsigned w = ctx->fb_state.width;
-   unsigned h = ctx->fb_state.height;
-
    util_copy_framebuffer_state(&ctx->fb_state, state);
-   if (ctx->fb_state.width != w || ctx->fb_state.height != h)
-      ctx->scissor_changed = true;
    rebind_fb_state(ctx, NULL, true);
    /* get_framebuffer adds a ref if the fb is reused or created;
     * always do get_framebuffer first to avoid deleting the same fb
@@ -2933,69 +2869,9 @@ zink_rebind_framebuffer(struct zink_context *ctx, struct zink_resource *res)
       zink_batch_no_rp(ctx);
 }
 
-static bool
-check_and_rebind_buffer(struct zink_context *ctx, struct zink_resource *res, unsigned shader, enum zink_descriptor_type type, unsigned i)
-{
-   bool is_write = false;
-   bool is_read = true;
-   struct zink_resource *cres = zink_get_resource_for_descriptor(ctx, type, shader, i);
-   if (res != cres)
-      return false;
-
-   switch (type) {
-   case ZINK_DESCRIPTOR_TYPE_SSBO: {
-      struct pipe_shader_buffer *ssbo = &ctx->ssbos[shader][i];
-      is_write = ctx->writable_ssbos[shader] & BITFIELD64_BIT(i);
-      util_range_add(&res->base.b, &res->valid_buffer_range, ssbo->buffer_offset,
-                     ssbo->buffer_offset + ssbo->buffer_size);
-      break;
-   }
-   case ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW: {
-      struct zink_sampler_view *sampler_view = zink_sampler_view(ctx->sampler_views[shader][i]);
-      sampler_view_buffer_clear(ctx, sampler_view);
-      sampler_view->buffer_view = get_buffer_view(ctx, res, sampler_view->base.format,
-                                                  sampler_view->base.u.buf.offset, sampler_view->base.u.buf.size);
-      break;
-   }
-   case ZINK_DESCRIPTOR_TYPE_IMAGE: {
-      struct zink_image_view *image_view = &ctx->image_views[shader][i];
-      zink_descriptor_set_refs_clear(&image_view->desc_set_refs, image_view);
-      zink_buffer_view_reference(zink_screen(ctx->base.screen), &image_view->buffer_view, NULL);
-      if (!zink_resource_object_init_storage(ctx, res)) {
-         debug_printf("couldn't create storage image!");
-         return false;
-      }
-      is_write = image_view->base.access & PIPE_IMAGE_ACCESS_WRITE;
-      is_read = image_view->base.access & PIPE_IMAGE_ACCESS_READ;
-      image_view->buffer_view = get_buffer_view(ctx, res, image_view->base.format,
-                                                image_view->base.u.buf.offset, image_view->base.u.buf.size);
-      assert(image_view->buffer_view);
-      util_range_add(&res->base.b, &res->valid_buffer_range, image_view->base.u.buf.offset,
-                     image_view->base.u.buf.offset + image_view->base.u.buf.size);
-      break;
-   }
-   default:
-      break;
-   }
-
-   zink_screen(ctx->base.screen)->context_invalidate_descriptor_state(ctx, shader, type, i, 1);
-   update_descriptor_state(ctx, shader, type, i);
-   zink_batch_reference_resource_rw(&ctx->batch, res, is_write);
-   VkAccessFlags access = 0;
-   if (is_read)
-      access |= VK_ACCESS_SHADER_READ_BIT;
-   if (is_write)
-      access |= VK_ACCESS_SHADER_WRITE_BIT;
-   zink_resource_buffer_barrier(ctx, NULL, res, access,
-                                zink_pipeline_flags_from_stage(zink_shader_stage(shader)));
-   return true;
-}
-
 static void
 rebind_buffer(struct zink_context *ctx, struct zink_resource *res)
 {
-   unsigned num_rebinds = 0;
-
    for (unsigned shader = 0; shader < PIPE_SHADER_TYPES; shader++) {
       if (!(res->bind_stages & (1 << shader)))
          continue;
@@ -3003,58 +2879,79 @@ rebind_buffer(struct zink_context *ctx, struct zink_resource *res)
          if (!(res->bind_history & BITFIELD64_BIT(type)))
             continue;
 
-         uint32_t usage = zink_program_get_descriptor_usage(ctx, shader, type);
-         u_foreach_bit(i, usage) {
-            if (check_and_rebind_buffer(ctx, res, shader, type, i))
-               num_rebinds++;
+         unsigned num_descriptors = 0;
+         switch (type) {
+         case ZINK_DESCRIPTOR_TYPE_UBO:
+            num_descriptors = ctx->di.num_ubos[shader];
+            break;
+         case ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW:
+            num_descriptors = ctx->di.num_sampler_views[shader];
+            break;
+         case ZINK_DESCRIPTOR_TYPE_SSBO:
+            num_descriptors = ctx->di.num_ssbos[shader];
+            break;
+         case ZINK_DESCRIPTOR_TYPE_IMAGE:
+            num_descriptors = ctx->di.num_images[shader];
+            break;
+         default:
+            unreachable("ack");
          }
-      }
-   }
-   unsigned total_binds = res->bind_count[0] + res->bind_count[1] - res->vbo_bind_count;
-   /* we've missed some rebinds, so we have to go back for them */
-   if (total_binds != num_rebinds) {
-      for (unsigned shader = 0; shader < PIPE_SHADER_TYPES; shader++) {
-         if (!(res->bind_stages & (1 << shader)))
-            continue;
-         for (enum zink_descriptor_type type = 0; type < ZINK_DESCRIPTOR_TYPES; type++) {
-            if (!(res->bind_history & BITFIELD64_BIT(type)))
+         for (unsigned i = 0; i < num_descriptors; i++) {
+            bool is_write = false;
+            bool is_read = true;
+            struct zink_resource *cres = zink_get_resource_for_descriptor(ctx, type, shader, i);
+            if (res != cres)
                continue;
 
-            unsigned num_descriptors = 0;
             switch (type) {
-            case ZINK_DESCRIPTOR_TYPE_UBO:
-               num_descriptors = ctx->di.num_ubos[shader];
+            case ZINK_DESCRIPTOR_TYPE_SSBO: {
+               struct pipe_shader_buffer *ssbo = &ctx->ssbos[shader][i];
+               is_write = ctx->writable_ssbos[shader] & BITFIELD64_BIT(i);
+               util_range_add(&res->base.b, &res->valid_buffer_range, ssbo->buffer_offset,
+                              ssbo->buffer_offset + ssbo->buffer_size);
                break;
-            case ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW:
-               num_descriptors = ctx->di.num_sampler_views[shader];
-               break;
-            case ZINK_DESCRIPTOR_TYPE_SSBO:
-               num_descriptors = ctx->di.num_ssbos[shader];
+            }
+            case ZINK_DESCRIPTOR_TYPE_SAMPLER_VIEW: {
+               struct zink_sampler_view *sampler_view = zink_sampler_view(ctx->sampler_views[shader][i]);
+               sampler_view_buffer_clear(ctx, sampler_view);
+               sampler_view->buffer_view = get_buffer_view(ctx, res, sampler_view->base.format,
+                                                           sampler_view->base.u.buf.offset, sampler_view->base.u.buf.size);
                break;
-            case ZINK_DESCRIPTOR_TYPE_IMAGE:
-               num_descriptors = ctx->di.num_images[shader];
+            }
+            case ZINK_DESCRIPTOR_TYPE_IMAGE: {
+               struct zink_image_view *image_view = &ctx->image_views[shader][i];
+               zink_descriptor_set_refs_clear(&image_view->desc_set_refs, image_view);
+               zink_buffer_view_reference(zink_screen(ctx->base.screen), &image_view->buffer_view, NULL);
+               if (!zink_resource_object_init_storage(ctx, res)) {
+                  debug_printf("couldn't create storage image!");
+                  continue;
+               }
+               is_write = image_view->base.access & PIPE_IMAGE_ACCESS_WRITE;
+               is_read = image_view->base.access & PIPE_IMAGE_ACCESS_READ;
+               image_view->buffer_view = get_buffer_view(ctx, res, image_view->base.format,
+                                                         image_view->base.u.buf.offset, image_view->base.u.buf.size);
+               assert(image_view->buffer_view);
+               util_range_add(&res->base.b, &res->valid_buffer_range, image_view->base.u.buf.offset,
+                              image_view->base.u.buf.offset + image_view->base.u.buf.size);
                break;
-            default:
-               unreachable("ack");
             }
-            for (unsigned i = 0; i < num_descriptors; i++) {
-               if (check_and_rebind_buffer(ctx, res, shader, type, i))
-                  num_rebinds++;
-               if (total_binds == num_rebinds)
-                  goto out;
+            default:
+               break;
             }
+
+            zink_screen(ctx->base.screen)->context_invalidate_descriptor_state(ctx, shader, type, i, 1);
+            update_descriptor_state(ctx, shader, type, i);
+            zink_batch_reference_resource_rw(&ctx->batch, res, is_write);
+            VkAccessFlags access = 0;
+            if (is_read)
+               access |= VK_ACCESS_SHADER_READ_BIT;
+            if (is_write)
+               access |= VK_ACCESS_SHADER_WRITE_BIT;
+            zink_resource_buffer_barrier(ctx, NULL, res, access,
+                                         zink_pipeline_flags_from_stage(zink_shader_stage(shader)));
          }
       }
    }
-out:
-   assert(total_binds == num_rebinds);
-   if (!res->vbo_bind_count)
-      return;
-   if (!num_rebinds)
-      zink_batch_reference_resource_rw(&ctx->batch, res, false);
-   ctx->vertex_buffers_dirty = true;
-   zink_resource_buffer_barrier(ctx, NULL, res, VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT,
-                                VK_PIPELINE_STAGE_VERTEX_INPUT_BIT);
 }
 
 static bool
diff --git a/src/gallium/drivers/zink/zink_context.h b/src/gallium/drivers/zink/zink_context.h
index e1d1e449591..6e9b9c92c16 100644
--- a/src/gallium/drivers/zink/zink_context.h
+++ b/src/gallium/drivers/zink/zink_context.h
@@ -166,7 +166,6 @@ struct zink_context {
    struct zink_depth_stencil_alpha_state *dsa_state;
 
    struct hash_table desc_set_layouts[ZINK_DESCRIPTOR_TYPES];
-   bool pipeline_changed[2]; //gfx, compute
 
    struct zink_shader *gfx_stages[ZINK_SHADER_COUNT];
    struct zink_gfx_pipeline_state gfx_pipeline_state;
@@ -197,14 +196,11 @@ struct zink_context {
    uint16_t rp_clears_enabled;
 
    struct pipe_vertex_buffer vertex_buffers[PIPE_MAX_ATTRIBS];
-   bool vertex_buffers_dirty;
 
    void *sampler_states[PIPE_SHADER_TYPES][PIPE_MAX_SAMPLERS];
    struct pipe_sampler_view *sampler_views[PIPE_SHADER_TYPES][PIPE_MAX_SAMPLERS];
 
    struct zink_viewport_state vp_state;
-   bool vp_state_changed;
-   bool scissor_changed;
 
    float line_width;
    float blend_constants[4];
diff --git a/src/gallium/drivers/zink/zink_draw.c b/src/gallium/drivers/zink/zink_draw.c
index 7357c39a27c..c15c7c3a144 100644
--- a/src/gallium/drivers/zink/zink_draw.c
+++ b/src/gallium/drivers/zink/zink_draw.c
@@ -143,6 +143,7 @@ zink_bind_vertex_buffers(struct zink_batch *batch, struct zink_context *ctx)
          buffers[i] = res->obj->buffer;
          buffer_offsets[i] = vb->buffer_offset;
          buffer_strides[i] = vb->stride;
+         zink_batch_reference_resource_rw(batch, res, false);
       } else {
          buffers[i] = zink_resource(ctx->dummy_vertex_buffer)->obj->buffer;
          buffer_offsets[i] = 0;
@@ -158,7 +159,6 @@ zink_bind_vertex_buffers(struct zink_batch *batch, struct zink_context *ctx)
       vkCmdBindVertexBuffers(batch->state->cmdbuf, 0,
                              elems->hw_state.num_bindings,
                              buffers, buffer_offsets);
-   ctx->vertex_buffers_dirty = false;
 }
 
 static struct zink_compute_program *
@@ -459,6 +459,17 @@ zink_draw_vbo(struct pipe_context *pctx,
       ctx->gfx_pipeline_state.dirty = true;
    ctx->gfx_pipeline_state.primitive_restart = !!dinfo->primitive_restart;
 
+   if (!zink_screen(pctx->screen)->info.have_EXT_extended_dynamic_state) {
+      for (unsigned i = 0; i < ctx->element_state->hw_state.num_bindings; i++) {
+         unsigned binding = ctx->element_state->binding_map[i];
+         const struct pipe_vertex_buffer *vb = ctx->vertex_buffers + binding;
+         if (ctx->gfx_pipeline_state.bindings[i].stride != vb->stride) {
+            ctx->gfx_pipeline_state.bindings[i].stride = vb->stride;
+            ctx->gfx_pipeline_state.dirty = true;
+         }
+      }
+   }
+
    enum pipe_prim_type reduced_prim = u_reduced_prim(dinfo->mode);
 
    bool depth_bias = false;
@@ -532,59 +543,44 @@ zink_draw_vbo(struct pipe_context *pctx,
       zink_update_descriptor_refs(ctx, false);
 
    struct zink_batch *batch = zink_batch_rp(ctx);
-
-   VkPipeline prev_pipeline = ctx->gfx_pipeline_state.pipeline;
-   VkPipeline pipeline = zink_get_gfx_pipeline(ctx, gfx_program,
-                                               &ctx->gfx_pipeline_state,
-                                               dinfo->mode);
-   bool pipeline_changed = prev_pipeline != pipeline || ctx->pipeline_changed[0];
-   if (pipeline_changed)
-      vkCmdBindPipeline(batch->state->cmdbuf, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);
-
-   if (ctx->vp_state_changed || pipeline_changed) {
-      VkViewport viewports[PIPE_MAX_VIEWPORTS];
+   VkViewport viewports[PIPE_MAX_VIEWPORTS];
+   for (unsigned i = 0; i < ctx->vp_state.num_viewports; i++) {
+      VkViewport viewport = {
+         ctx->vp_state.viewport_states[i].translate[0] - ctx->vp_state.viewport_states[i].scale[0],
+         ctx->vp_state.viewport_states[i].translate[1] - ctx->vp_state.viewport_states[i].scale[1],
+         ctx->vp_state.viewport_states[i].scale[0] * 2,
+         ctx->vp_state.viewport_states[i].scale[1] * 2,
+         ctx->rast_state->base.clip_halfz ?
+            ctx->vp_state.viewport_states[i].translate[2] :
+            ctx->vp_state.viewport_states[i].translate[2] - ctx->vp_state.viewport_states[i].scale[2],
+         ctx->vp_state.viewport_states[i].translate[2] + ctx->vp_state.viewport_states[i].scale[2]
+      };
+      viewports[i] = viewport;
+   }
+   if (screen->info.have_EXT_extended_dynamic_state)
+      screen->vk_CmdSetViewportWithCountEXT(batch->state->cmdbuf, ctx->vp_state.num_viewports, viewports);
+   else
+      vkCmdSetViewport(batch->state->cmdbuf, 0, ctx->vp_state.num_viewports, viewports);
+   VkRect2D scissors[PIPE_MAX_VIEWPORTS];
+   if (ctx->rast_state->base.scissor) {
       for (unsigned i = 0; i < ctx->vp_state.num_viewports; i++) {
-         VkViewport viewport = {
-            ctx->vp_state.viewport_states[i].translate[0] - ctx->vp_state.viewport_states[i].scale[0],
-            ctx->vp_state.viewport_states[i].translate[1] - ctx->vp_state.viewport_states[i].scale[1],
-            ctx->vp_state.viewport_states[i].scale[0] * 2,
-            ctx->vp_state.viewport_states[i].scale[1] * 2,
-            ctx->rast_state->base.clip_halfz ?
-               ctx->vp_state.viewport_states[i].translate[2] :
-               ctx->vp_state.viewport_states[i].translate[2] - ctx->vp_state.viewport_states[i].scale[2],
-            ctx->vp_state.viewport_states[i].translate[2] + ctx->vp_state.viewport_states[i].scale[2]
-         };
-         viewports[i] = viewport;
+         scissors[i].offset.x = ctx->vp_state.scissor_states[i].minx;
+         scissors[i].offset.y = ctx->vp_state.scissor_states[i].miny;
+         scissors[i].extent.width = ctx->vp_state.scissor_states[i].maxx - ctx->vp_state.scissor_states[i].minx;
+         scissors[i].extent.height = ctx->vp_state.scissor_states[i].maxy - ctx->vp_state.scissor_states[i].miny;
       }
-      if (screen->info.have_EXT_extended_dynamic_state)
-         screen->vk_CmdSetViewportWithCountEXT(batch->state->cmdbuf, ctx->vp_state.num_viewports, viewports);
-      else
-         vkCmdSetViewport(batch->state->cmdbuf, 0, ctx->vp_state.num_viewports, viewports);
-   }
-   if (ctx->scissor_changed || ctx->vp_state_changed || pipeline_changed) {
-      VkRect2D scissors[PIPE_MAX_VIEWPORTS];
-      if (ctx->rast_state->base.scissor) {
-         for (unsigned i = 0; i < ctx->vp_state.num_viewports; i++) {
-            scissors[i].offset.x = ctx->vp_state.scissor_states[i].minx;
-            scissors[i].offset.y = ctx->vp_state.scissor_states[i].miny;
-            scissors[i].extent.width = ctx->vp_state.scissor_states[i].maxx - ctx->vp_state.scissor_states[i].minx;
-            scissors[i].extent.height = ctx->vp_state.scissor_states[i].maxy - ctx->vp_state.scissor_states[i].miny;
-         }
-      } else {
-         for (unsigned i = 0; i < ctx->vp_state.num_viewports; i++) {
-            scissors[i].offset.x = 0;
-            scissors[i].offset.y = 0;
-            scissors[i].extent.width = ctx->fb_state.width;
-            scissors[i].extent.height = ctx->fb_state.height;
-         }
+   } else {
+      for (unsigned i = 0; i < ctx->vp_state.num_viewports; i++) {
+         scissors[i].offset.x = 0;
+         scissors[i].offset.y = 0;
+         scissors[i].extent.width = ctx->fb_state.width;
+         scissors[i].extent.height = ctx->fb_state.height;
       }
-      if (screen->info.have_EXT_extended_dynamic_state)
-         screen->vk_CmdSetScissorWithCountEXT(batch->state->cmdbuf, ctx->vp_state.num_viewports, scissors);
-      else
-         vkCmdSetScissor(batch->state->cmdbuf, 0, ctx->vp_state.num_viewports, scissors);
    }
-   ctx->vp_state_changed = false;
-   ctx->scissor_changed = false;
+   if (screen->info.have_EXT_extended_dynamic_state)
+      screen->vk_CmdSetScissorWithCountEXT(batch->state->cmdbuf, ctx->vp_state.num_viewports, scissors);
+   else
+      vkCmdSetScissor(batch->state->cmdbuf, 0, ctx->vp_state.num_viewports, scissors);
 
    if (line_width_needed(reduced_prim, rast_state->hw_state.polygon_mode)) {
       if (screen->info.feats.features.wideLines || ctx->line_width == 1.0f)
@@ -605,43 +601,6 @@ zink_draw_vbo(struct pipe_context *pctx,
                                   ctx->stencil_ref.ref_value[0]);
    }
 
-   if (screen->info.have_EXT_extended_dynamic_state) {
-      screen->vk_CmdSetDepthBoundsTestEnableEXT(batch->state->cmdbuf, dsa_state->hw_state.depth_bounds_test);
-      if (dsa_state->hw_state.depth_bounds_test)
-         vkCmdSetDepthBounds(batch->state->cmdbuf,
-                             dsa_state->hw_state.min_depth_bounds,
-                             dsa_state->hw_state.max_depth_bounds);
-      screen->vk_CmdSetDepthTestEnableEXT(batch->state->cmdbuf, dsa_state->hw_state.depth_test);
-      if (dsa_state->hw_state.depth_test)
-         screen->vk_CmdSetDepthCompareOpEXT(batch->state->cmdbuf, dsa_state->hw_state.depth_compare_op);
-      screen->vk_CmdSetDepthWriteEnableEXT(batch->state->cmdbuf, dsa_state->hw_state.depth_write);
-      screen->vk_CmdSetStencilTestEnableEXT(batch->state->cmdbuf, dsa_state->hw_state.stencil_test);
-      if (dsa_state->hw_state.stencil_test) {
-         screen->vk_CmdSetStencilOpEXT(batch->state->cmdbuf, VK_STENCIL_FACE_FRONT_BIT,
-                                       dsa_state->hw_state.stencil_front.failOp,
-                                       dsa_state->hw_state.stencil_front.passOp,
-                                       dsa_state->hw_state.stencil_front.depthFailOp,
-                                       dsa_state->hw_state.stencil_front.compareOp);
-         screen->vk_CmdSetStencilOpEXT(batch->state->cmdbuf, VK_STENCIL_FACE_BACK_BIT,
-                                       dsa_state->hw_state.stencil_back.failOp,
-                                       dsa_state->hw_state.stencil_back.passOp,
-                                       dsa_state->hw_state.stencil_back.depthFailOp,
-                                       dsa_state->hw_state.stencil_back.compareOp);
-      }
-      if (dsa_state->base.stencil[0].enabled) {
-         if (dsa_state->base.stencil[1].enabled) {
-            vkCmdSetStencilWriteMask(batch->state->cmdbuf, VK_STENCIL_FACE_FRONT_BIT, dsa_state->hw_state.stencil_front.writeMask);
-            vkCmdSetStencilWriteMask(batch->state->cmdbuf, VK_STENCIL_FACE_BACK_BIT, dsa_state->hw_state.stencil_back.writeMask);
-            vkCmdSetStencilCompareMask(batch->state->cmdbuf, VK_STENCIL_FACE_FRONT_BIT, dsa_state->hw_state.stencil_front.compareMask);
-            vkCmdSetStencilCompareMask(batch->state->cmdbuf, VK_STENCIL_FACE_BACK_BIT, dsa_state->hw_state.stencil_back.compareMask);
-         } else {
-            vkCmdSetStencilWriteMask(batch->state->cmdbuf, VK_STENCIL_FACE_FRONT_AND_BACK, dsa_state->hw_state.stencil_front.writeMask);
-            vkCmdSetStencilCompareMask(batch->state->cmdbuf, VK_STENCIL_FACE_FRONT_AND_BACK, dsa_state->hw_state.stencil_front.compareMask);
-         }
-      }
-      screen->vk_CmdSetFrontFaceEXT(batch->state->cmdbuf, ctx->gfx_pipeline_state.front_face);
-   }
-
    if (depth_bias)
       vkCmdSetDepthBias(batch->state->cmdbuf, rast_state->offset_units, rast_state->offset_clamp, rast_state->offset_scale);
    else
@@ -650,8 +609,13 @@ zink_draw_vbo(struct pipe_context *pctx,
    if (ctx->gfx_pipeline_state.blend_state->need_blend_constants)
       vkCmdSetBlendConstants(batch->state->cmdbuf, ctx->blend_constants);
 
-   if (ctx->vertex_buffers_dirty || pipeline_changed)
-      zink_bind_vertex_buffers(batch, ctx);
+
+   VkPipeline pipeline = zink_get_gfx_pipeline(screen, gfx_program,
+                                               &ctx->gfx_pipeline_state,
+                                               dinfo->mode);
+   vkCmdBindPipeline(batch->state->cmdbuf, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);
+
+   zink_bind_vertex_buffers(batch, ctx);
 
    if (BITSET_TEST(ctx->gfx_stages[PIPE_SHADER_VERTEX]->nir->info.system_values_read, SYSTEM_VALUE_BASE_VERTEX)) {
       unsigned draw_mode_is_indexed = dinfo->index_size > 0;
@@ -682,8 +646,6 @@ zink_draw_vbo(struct pipe_context *pctx,
       screen->vk_CmdBeginTransformFeedbackEXT(batch->state->cmdbuf, 0, ctx->num_so_targets, counter_buffers, counter_buffer_offsets);
    }
 
-   ctx->pipeline_changed[0] = false;
-
    unsigned draw_id = drawid_offset;
    bool needs_drawid = ctx->drawid_broken;
    batch->state->work_count[0] += num_draws;
@@ -791,7 +753,6 @@ zink_launch_grid(struct pipe_context *pctx, const struct pipe_grid_info *info)
       return;
 
    zink_program_update_compute_pipeline_state(ctx, comp_program, info->block);
-   VkPipeline prev_pipeline = ctx->compute_pipeline_state.pipeline;
    VkPipeline pipeline = zink_get_compute_pipeline(screen, comp_program,
                                                &ctx->compute_pipeline_state);
 
@@ -801,9 +762,7 @@ zink_launch_grid(struct pipe_context *pctx, const struct pipe_grid_info *info)
    if (ctx->descriptor_refs_dirty[1])
       zink_update_descriptor_refs(ctx, true);
 
-   if (prev_pipeline != pipeline || ctx->pipeline_changed[1])
-      vkCmdBindPipeline(batch->state->cmdbuf, VK_PIPELINE_BIND_POINT_COMPUTE, pipeline);
-   ctx->pipeline_changed[1] = false;
+   vkCmdBindPipeline(batch->state->cmdbuf, VK_PIPELINE_BIND_POINT_COMPUTE, pipeline);
 
    if (BITSET_TEST(comp_program->shader->nir->info.system_values_read, SYSTEM_VALUE_WORK_DIM))
       vkCmdPushConstants(batch->state->cmdbuf, comp_program->base.layout, VK_SHADER_STAGE_COMPUTE_BIT,
diff --git a/src/gallium/drivers/zink/zink_pipeline.c b/src/gallium/drivers/zink/zink_pipeline.c
index 6264ccbceb9..1a1b197b059 100644
--- a/src/gallium/drivers/zink/zink_pipeline.c
+++ b/src/gallium/drivers/zink/zink_pipeline.c
@@ -43,17 +43,17 @@ zink_create_gfx_pipeline(struct zink_screen *screen,
 {
    VkPipelineVertexInputStateCreateInfo vertex_input_state = {};
    vertex_input_state.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
-   vertex_input_state.pVertexBindingDescriptions = state->element_state->bindings;
+   vertex_input_state.pVertexBindingDescriptions = state->bindings;
    vertex_input_state.vertexBindingDescriptionCount = state->element_state->num_bindings;
    vertex_input_state.pVertexAttributeDescriptions = state->element_state->attribs;
    vertex_input_state.vertexAttributeDescriptionCount = state->element_state->num_attribs;
 
    VkPipelineVertexInputDivisorStateCreateInfoEXT vdiv_state = {};
-   if (state->element_state->divisors_present) {
+   if (state->divisors_present) {
        vertex_input_state.pNext = &vdiv_state;
        vdiv_state.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO_EXT;
-       vdiv_state.vertexBindingDivisorCount = state->element_state->divisors_present;
-       vdiv_state.pVertexBindingDivisors = state->element_state->divisors;
+       vdiv_state.vertexBindingDivisorCount = state->divisors_present;
+       vdiv_state.pVertexBindingDivisors = state->divisors;
    }
 
    VkPipelineInputAssemblyStateCreateInfo primitive_state = {};
@@ -106,7 +106,7 @@ zink_create_gfx_pipeline(struct zink_screen *screen,
    rast_state.rasterizerDiscardEnable = state->rast_state->rasterizer_discard;
    rast_state.polygonMode = state->rast_state->polygon_mode;
    rast_state.cullMode = state->rast_state->cull_mode;
-   rast_state.frontFace = state->front_face;
+   rast_state.frontFace = state->rast_state->front_face;
 
    rast_state.depthBiasEnable = VK_TRUE;
    rast_state.depthBiasConstantFactor = 0.0;
@@ -145,17 +145,7 @@ zink_create_gfx_pipeline(struct zink_screen *screen,
    if (screen->info.have_EXT_extended_dynamic_state) {
       dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_VIEWPORT_WITH_COUNT_EXT;
       dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_SCISSOR_WITH_COUNT_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_DEPTH_BOUNDS;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_DEPTH_BOUNDS_TEST_ENABLE_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_DEPTH_COMPARE_OP_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_DEPTH_TEST_ENABLE_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_DEPTH_WRITE_ENABLE_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_STENCIL_WRITE_MASK;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_STENCIL_COMPARE_MASK;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_STENCIL_OP_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_STENCIL_TEST_ENABLE_EXT;
       dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_VERTEX_INPUT_BINDING_STRIDE_EXT;
-      dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_FRONT_FACE_EXT;
    } else {
       dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_VIEWPORT;
       dynamicStateEnables[state_count++] = VK_DYNAMIC_STATE_SCISSOR;
diff --git a/src/gallium/drivers/zink/zink_pipeline.h b/src/gallium/drivers/zink/zink_pipeline.h
index 0c39acc30e3..1f8b62f6a17 100644
--- a/src/gallium/drivers/zink/zink_pipeline.h
+++ b/src/gallium/drivers/zink/zink_pipeline.h
@@ -40,11 +40,16 @@ struct zink_vertex_elements_state;
 struct zink_gfx_pipeline_state {
    struct zink_render_pass *render_pass;
 
+   struct zink_vertex_elements_hw_state *element_state;
+   uint8_t divisors_present;
+
    uint32_t num_attachments;
    struct zink_blend_state *blend_state;
 
    struct zink_rasterizer_hw_state *rast_state;
 
+   struct zink_depth_stencil_alpha_hw_state *depth_stencil_alpha_state;
+
    VkSampleMask sample_mask;
    uint8_t rast_samples;
    uint8_t vertices_per_patch;
@@ -58,26 +63,16 @@ struct zink_gfx_pipeline_state {
    uint32_t hash;
    bool dirty;
 
-   struct zink_depth_stencil_alpha_hw_state *depth_stencil_alpha_state; //non-dynamic state
-   VkFrontFace front_face;
-
    VkShaderModule modules[PIPE_SHADER_TYPES - 1];
    uint32_t module_hash;
 
    uint32_t combined_hash;
    bool combined_dirty;
 
-   struct zink_vertex_elements_hw_state *element_state;
-   bool vertex_state_dirty;
-
-   uint32_t final_hash;
-
+   VkVertexInputBindingDivisorDescriptionEXT divisors[PIPE_MAX_ATTRIBS];
+   VkVertexInputBindingDescription bindings[PIPE_MAX_ATTRIBS]; // combination of element_state and stride
    uint32_t vertex_buffers_enabled_mask;
-   uint32_t vertex_strides[PIPE_MAX_ATTRIBS];
    bool have_EXT_extended_dynamic_state;
-
-   VkPipeline pipeline;
-   enum pipe_prim_type mode;
 };
 
 struct zink_compute_pipeline_state {
@@ -87,8 +82,6 @@ struct zink_compute_pipeline_state {
    bool dirty;
    bool use_local_size;
    uint32_t local_size[3];
-
-   VkPipeline pipeline;
 };
 
 VkPipeline
diff --git a/src/gallium/drivers/zink/zink_program.c b/src/gallium/drivers/zink/zink_program.c
index eb095e05305..5bd5261e2b5 100644
--- a/src/gallium/drivers/zink/zink_program.c
+++ b/src/gallium/drivers/zink/zink_program.c
@@ -372,10 +372,19 @@ static uint32_t
 hash_gfx_pipeline_state(const void *key)
 {
    const struct zink_gfx_pipeline_state *state = key;
-   uint32_t hash = _mesa_hash_data(key, offsetof(struct zink_gfx_pipeline_state, hash));
-   if (state->have_EXT_extended_dynamic_state)
-      return hash;
-   return XXH32(&state->depth_stencil_alpha_state, sizeof(void*), hash);
+   uint32_t hash = 0;
+   if (!state->have_EXT_extended_dynamic_state) {
+      /* if we don't have dynamic states, we have to hash the enabled vertex buffer bindings */
+      uint32_t vertex_buffers_enabled_mask = state->vertex_buffers_enabled_mask;
+      hash = XXH32(&vertex_buffers_enabled_mask, sizeof(uint32_t), hash);
+      while (vertex_buffers_enabled_mask) {
+         unsigned idx = u_bit_scan(&vertex_buffers_enabled_mask);
+         hash = XXH32(&state->bindings[idx], sizeof(VkVertexInputBindingDescription), hash);
+      }
+   }
+   for (unsigned i = 0; i < state->divisors_present; i++)
+      hash = XXH32(&state->divisors[i], sizeof(VkVertexInputBindingDivisorDescriptionEXT), hash);
+   return _mesa_hash_data(key, offsetof(struct zink_gfx_pipeline_state, hash));
 }
 
 static bool
@@ -383,23 +392,30 @@ equals_gfx_pipeline_state(const void *a, const void *b)
 {
    const struct zink_gfx_pipeline_state *sa = a;
    const struct zink_gfx_pipeline_state *sb = b;
+   if (sa->vertex_buffers_enabled_mask != sb->vertex_buffers_enabled_mask)
+      return false;
    if (!sa->have_EXT_extended_dynamic_state) {
-      if (sa->vertex_buffers_enabled_mask != sb->vertex_buffers_enabled_mask)
-         return false;
       /* if we don't have dynamic states, we have to hash the enabled vertex buffer bindings */
       uint32_t mask_a = sa->vertex_buffers_enabled_mask;
       uint32_t mask_b = sb->vertex_buffers_enabled_mask;
       while (mask_a || mask_b) {
          unsigned idx_a = u_bit_scan(&mask_a);
          unsigned idx_b = u_bit_scan(&mask_b);
-         if (sa->vertex_strides[idx_a] != sb->vertex_strides[idx_b])
+         if (memcmp(&sa->bindings[idx_a], &sb->bindings[idx_b], sizeof(VkVertexInputBindingDescription)))
+            return false;
+      }
+   }
+   if (sa->divisors_present != sb->divisors_present)
+      return false;
+   if (sa->divisors_present && sb->divisors_present) {
+      uint32_t divisors_present_a = sa->divisors_present;
+      uint32_t divisors_present_b = sb->divisors_present;
+      while (divisors_present_a || divisors_present_b) {
+         unsigned idx_a = u_bit_scan(&divisors_present_a);
+         unsigned idx_b = u_bit_scan(&divisors_present_b);
+         if (memcmp(&sa->divisors[idx_a], &sb->divisors[idx_b], sizeof(VkVertexInputBindingDivisorDescriptionEXT)))
             return false;
       }
-      if (sa->front_face != sb->front_face)
-         return false;
-      if (!!sa->depth_stencil_alpha_state != !!sb->depth_stencil_alpha_state ||
-          (sa && sb && memcmp(sa->depth_stencil_alpha_state, sb->depth_stencil_alpha_state, sizeof(struct zink_depth_stencil_alpha_hw_state))))
-         return false;
    }
    return !memcmp(sa->modules, sb->modules, sizeof(sa->modules)) &&
           !memcmp(a, b, offsetof(struct zink_gfx_pipeline_state, hash));
@@ -869,47 +885,26 @@ primitive_topology(enum pipe_prim_type mode)
 }
 
 VkPipeline
-zink_get_gfx_pipeline(struct zink_context *ctx,
+zink_get_gfx_pipeline(struct zink_screen *screen,
                       struct zink_gfx_program *prog,
                       struct zink_gfx_pipeline_state *state,
                       enum pipe_prim_type mode)
 {
-   if (!state->dirty && !state->combined_dirty && !state->vertex_state_dirty && mode == state->mode)
-      return state->pipeline;
-
-   struct zink_screen *screen = zink_screen(ctx->base.screen);
    VkPrimitiveTopology vkmode = primitive_topology(mode);
    assert(vkmode <= ARRAY_SIZE(prog->pipelines));
 
    struct hash_entry *entry = NULL;
 
    if (state->dirty) {
-      state->vertex_state_dirty = state->combined_dirty = true;
+      state->combined_dirty = true;
       state->hash = hash_gfx_pipeline_state(state);
       state->dirty = false;
    }
    if (state->combined_dirty) {
-      state->vertex_state_dirty = true;
       state->combined_hash = XXH32(&state->module_hash, sizeof(uint32_t), state->hash);
       state->combined_dirty = false;
    }
-   if (state->vertex_state_dirty) {
-      uint32_t hash = state->combined_hash;
-      if (!state->have_EXT_extended_dynamic_state) {
-         /* if we don't have dynamic states, we have to hash the enabled vertex buffer bindings */
-         uint32_t vertex_buffers_enabled_mask = state->vertex_buffers_enabled_mask;
-         hash = XXH32(&vertex_buffers_enabled_mask, sizeof(uint32_t), hash);
-
-         for (unsigned i = 0; i < state->element_state->num_bindings; i++) {
-            struct pipe_vertex_buffer *vb = ctx->vertex_buffers + ctx->element_state->binding_map[i];
-            state->vertex_strides[i] = vb->buffer.resource ? vb->stride : 0;
-            hash = XXH32(&state->vertex_strides[i], sizeof(uint32_t), hash);
-         }
-      }
-      state->final_hash = XXH32(&state->element_state, sizeof(void*), hash);
-      state->vertex_state_dirty = false;
-   }
-   entry = _mesa_hash_table_search_pre_hashed(prog->pipelines[vkmode], state->final_hash, state);
+   entry = _mesa_hash_table_search_pre_hashed(prog->pipelines[vkmode], state->combined_hash, state);
 
    if (!entry) {
       VkPipeline pipeline = zink_create_gfx_pipeline(screen, prog,
@@ -924,14 +919,11 @@ zink_get_gfx_pipeline(struct zink_context *ctx,
       memcpy(&pc_entry->state, state, sizeof(*state));
       pc_entry->pipeline = pipeline;
 
-      entry = _mesa_hash_table_insert_pre_hashed(prog->pipelines[vkmode], state->final_hash, state, pc_entry);
+      entry = _mesa_hash_table_insert_pre_hashed(prog->pipelines[vkmode], state->combined_hash, state, pc_entry);
       assert(entry);
    }
 
-   struct gfx_pipeline_cache_entry *cache_entry = entry->data;
-   state->pipeline = cache_entry->pipeline;
-   state->mode = mode;
-   return state->pipeline;
+   return ((struct gfx_pipeline_cache_entry *)(entry->data))->pipeline;
 }
 
 VkPipeline
@@ -941,8 +933,6 @@ zink_get_compute_pipeline(struct zink_screen *screen,
 {
    struct hash_entry *entry = NULL;
 
-   if (!state->dirty)
-      return state->pipeline;
    if (state->dirty) {
       state->hash = hash_compute_pipeline_state(state);
       state->dirty = false;
@@ -966,9 +956,7 @@ zink_get_compute_pipeline(struct zink_screen *screen,
       assert(entry);
    }
 
-   struct compute_pipeline_cache_entry *cache_entry = entry->data;
-   state->pipeline = cache_entry->pipeline;
-   return state->pipeline;
+   return ((struct compute_pipeline_cache_entry *)(entry->data))->pipeline;
 }
 
 
diff --git a/src/gallium/drivers/zink/zink_program.h b/src/gallium/drivers/zink/zink_program.h
index 43199c3ab7d..303c8f47e02 100644
--- a/src/gallium/drivers/zink/zink_program.h
+++ b/src/gallium/drivers/zink/zink_program.h
@@ -149,7 +149,7 @@ zink_destroy_gfx_program(struct zink_screen *screen,
                          struct zink_gfx_program *prog);
 
 VkPipeline
-zink_get_gfx_pipeline(struct zink_context *ctx,
+zink_get_gfx_pipeline(struct zink_screen *screen,
                       struct zink_gfx_program *prog,
                       struct zink_gfx_pipeline_state *state,
                       enum pipe_prim_type mode);
diff --git a/src/gallium/drivers/zink/zink_screen.c b/src/gallium/drivers/zink/zink_screen.c
index 91ad38cdc5d..832cd2c8994 100644
--- a/src/gallium/drivers/zink/zink_screen.c
+++ b/src/gallium/drivers/zink/zink_screen.c
@@ -1249,14 +1249,7 @@ load_device_extensions(struct zink_screen *screen)
    if (screen->info.have_EXT_extended_dynamic_state) {
       GET_PROC_ADDR(CmdSetViewportWithCountEXT);
       GET_PROC_ADDR(CmdSetScissorWithCountEXT);
-      GET_PROC_ADDR(CmdSetDepthBoundsTestEnableEXT);
-      GET_PROC_ADDR(CmdSetDepthCompareOpEXT);
-      GET_PROC_ADDR(CmdSetDepthTestEnableEXT);
-      GET_PROC_ADDR(CmdSetDepthWriteEnableEXT);
-      GET_PROC_ADDR(CmdSetStencilOpEXT);
-      GET_PROC_ADDR(CmdSetStencilTestEnableEXT);
       GET_PROC_ADDR(CmdBindVertexBuffers2EXT);
-      GET_PROC_ADDR(CmdSetFrontFaceEXT);
    }
 
    if (screen->info.have_EXT_image_drm_format_modifier)
@@ -1689,7 +1682,6 @@ zink_internal_create_screen(const struct pipe_screen_config *config)
    screen->base.context_create = zink_context_create;
    screen->base.flush_frontbuffer = zink_flush_frontbuffer;
    screen->base.destroy = zink_destroy_screen;
-   screen->base.finalize_nir = zink_shader_finalize;
 
    if (!zink_screen_resource_init(&screen->base))
       goto fail;
diff --git a/src/gallium/drivers/zink/zink_screen.h b/src/gallium/drivers/zink/zink_screen.h
index 1c4fb29cac5..748095035bb 100644
--- a/src/gallium/drivers/zink/zink_screen.h
+++ b/src/gallium/drivers/zink/zink_screen.h
@@ -161,14 +161,7 @@ struct zink_screen {
 
    PFN_vkCmdSetViewportWithCountEXT vk_CmdSetViewportWithCountEXT;
    PFN_vkCmdSetScissorWithCountEXT vk_CmdSetScissorWithCountEXT;
-   PFN_vkCmdSetDepthBoundsTestEnableEXT vk_CmdSetDepthBoundsTestEnableEXT;
-   PFN_vkCmdSetDepthCompareOpEXT vk_CmdSetDepthCompareOpEXT;
-   PFN_vkCmdSetDepthTestEnableEXT vk_CmdSetDepthTestEnableEXT;
-   PFN_vkCmdSetDepthWriteEnableEXT vk_CmdSetDepthWriteEnableEXT;
-   PFN_vkCmdSetStencilTestEnableEXT vk_CmdSetStencilTestEnableEXT;
-   PFN_vkCmdSetStencilOpEXT vk_CmdSetStencilOpEXT;
    PFN_vkCmdBindVertexBuffers2EXT vk_CmdBindVertexBuffers2EXT;
-   PFN_vkCmdSetFrontFaceEXT vk_CmdSetFrontFaceEXT;
 
    PFN_vkCreateDebugUtilsMessengerEXT vk_CreateDebugUtilsMessengerEXT;
    PFN_vkDestroyDebugUtilsMessengerEXT vk_DestroyDebugUtilsMessengerEXT;
diff --git a/src/gallium/drivers/zink/zink_state.c b/src/gallium/drivers/zink/zink_state.c
index 084f244f022..7ef71618dd9 100644
--- a/src/gallium/drivers/zink/zink_state.c
+++ b/src/gallium/drivers/zink/zink_state.c
@@ -76,15 +76,6 @@ zink_create_vertex_elements_state(struct pipe_context *pctx,
 
    ves->hw_state.num_bindings = num_bindings;
    ves->hw_state.num_attribs = num_elements;
-   for (int i = 0; i < num_bindings; ++i) {
-      ves->hw_state.bindings[i].binding = ves->bindings[i].binding;
-      ves->hw_state.bindings[i].inputRate = ves->bindings[i].inputRate;
-      if (ves->divisor[i]) {
-         ves->hw_state.divisors[ves->hw_state.divisors_present].divisor = ves->divisor[i];
-         ves->hw_state.divisors[ves->hw_state.divisors_present].binding = ves->bindings[i].binding;
-         ves->hw_state.divisors_present++;
-      }
-   }
    return ves;
 }
 
@@ -95,16 +86,22 @@ zink_bind_vertex_elements_state(struct pipe_context *pctx,
    struct zink_context *ctx = zink_context(pctx);
    struct zink_gfx_pipeline_state *state = &ctx->gfx_pipeline_state;
    ctx->element_state = cso;
+   state->dirty = true;
+   state->divisors_present = 0;
    if (cso) {
-      if (state->element_state != &ctx->element_state->hw_state) {
-         state->vertex_state_dirty = true;
-         ctx->vertex_buffers_dirty = ctx->element_state->hw_state.num_bindings > 0;
-      }
       state->element_state = &ctx->element_state->hw_state;
-   } else {
+      struct zink_vertex_elements_state *ves = cso;
+      for (int i = 0; i < state->element_state->num_bindings; ++i) {
+         state->bindings[i].binding = ves->bindings[i].binding;
+         state->bindings[i].inputRate = ves->bindings[i].inputRate;
+         if (ves->divisor[i]) {
+            state->divisors[state->divisors_present].divisor = ves->divisor[i];
+            state->divisors[state->divisors_present].binding = state->bindings[i].binding;
+            state->divisors_present++;
+         }
+      }
+   } else
      state->element_state = NULL;
-     ctx->vertex_buffers_dirty = false;
-   }
 }
 
 static void
@@ -395,7 +392,7 @@ zink_bind_depth_stencil_alpha_state(struct pipe_context *pctx, void *cso)
       struct zink_gfx_pipeline_state *state = &ctx->gfx_pipeline_state;
       if (state->depth_stencil_alpha_state != &ctx->dsa_state->hw_state) {
          state->depth_stencil_alpha_state = &ctx->dsa_state->hw_state;
-         state->dirty |= !zink_screen(pctx->screen)->info.have_EXT_extended_dynamic_state;
+         state->dirty = true;
       }
    }
 }
@@ -449,9 +446,9 @@ zink_create_rasterizer_state(struct pipe_context *pctx,
    state->hw_state.polygon_mode = (VkPolygonMode)rs_state->fill_front; // same values
    state->hw_state.cull_mode = (VkCullModeFlags)rs_state->cull_face; // same bits
 
-   state->front_face = rs_state->front_ccw ?
-                       VK_FRONT_FACE_COUNTER_CLOCKWISE :
-                       VK_FRONT_FACE_CLOCKWISE;
+   state->hw_state.front_face = rs_state->front_ccw ?
+                                VK_FRONT_FACE_COUNTER_CLOCKWISE :
+                                VK_FRONT_FACE_CLOCKWISE;
 
    state->offset_point = rs_state->offset_point;
    state->offset_line = rs_state->offset_line;
@@ -474,7 +471,6 @@ zink_bind_rasterizer_state(struct pipe_context *pctx, void *cso)
    struct zink_screen *screen = zink_screen(pctx->screen);
    bool clip_halfz = ctx->rast_state ? ctx->rast_state->base.clip_halfz : false;
    bool point_quad_rasterization = ctx->rast_state ? ctx->rast_state->base.point_quad_rasterization : false;
-   bool scissor = ctx->rast_state ? ctx->rast_state->base.scissor : false;
    ctx->rast_state = cso;
 
    if (ctx->rast_state) {
@@ -489,23 +485,15 @@ zink_bind_rasterizer_state(struct pipe_context *pctx, void *cso)
          ctx->gfx_pipeline_state.dirty = true;
       }
 
-      if (clip_halfz != ctx->rast_state->base.clip_halfz) {
+      if (clip_halfz != ctx->rast_state->base.clip_halfz)
          ctx->last_vertex_stage_dirty = true;
-         ctx->vp_state_changed = true;
-      }
 
-      if (ctx->gfx_pipeline_state.front_face != ctx->rast_state->front_face) {
-         ctx->gfx_pipeline_state.front_face = ctx->rast_state->front_face;
-         ctx->gfx_pipeline_state.dirty |= !zink_screen(pctx->screen)->info.have_EXT_extended_dynamic_state;
-      }
       if (ctx->line_width != ctx->rast_state->line_width) {
          ctx->line_width = ctx->rast_state->line_width;
          ctx->gfx_pipeline_state.dirty = true;
       }
       if (ctx->rast_state->base.point_quad_rasterization != point_quad_rasterization)
          ctx->dirty_shader_stages |= BITFIELD_BIT(PIPE_SHADER_FRAGMENT);
-      if (ctx->rast_state->base.scissor != scissor)
-         ctx->scissor_changed = true;
    }
 }
 
diff --git a/src/gallium/drivers/zink/zink_state.h b/src/gallium/drivers/zink/zink_state.h
index 7a200a5c6d7..998623d80a5 100644
--- a/src/gallium/drivers/zink/zink_state.h
+++ b/src/gallium/drivers/zink/zink_state.h
@@ -30,10 +30,7 @@
 
 struct zink_vertex_elements_hw_state {
    VkVertexInputAttributeDescription attribs[PIPE_MAX_ATTRIBS];
-   VkVertexInputBindingDivisorDescriptionEXT divisors[PIPE_MAX_ATTRIBS];
-   VkVertexInputBindingDescription bindings[PIPE_MAX_ATTRIBS]; // combination of element_state and stride
    uint32_t num_bindings, num_attribs;
-   uint8_t divisors_present;
 };
 
 struct zink_vertex_elements_state {
@@ -49,6 +46,7 @@ struct zink_vertex_elements_state {
 struct zink_rasterizer_hw_state {
    VkBool32 depth_clamp;
    VkBool32 rasterizer_discard;
+   VkFrontFace front_face;
    VkPolygonMode polygon_mode;
    VkCullModeFlags cull_mode;
    VkProvokingVertexModeEXT pv_mode;
@@ -60,7 +58,6 @@ struct zink_rasterizer_state {
    bool offset_point, offset_line, offset_tri;
    float offset_units, offset_clamp, offset_scale;
    float line_width;
-   VkFrontFace front_face;
    struct zink_rasterizer_hw_state hw_state;
 };
 
diff --git a/src/gallium/targets/libgl-xlib/meson.build b/src/gallium/targets/libgl-xlib/meson.build
index 7f161f7791a..ec9c13ea9b6 100644
--- a/src/gallium/targets/libgl-xlib/meson.build
+++ b/src/gallium/targets/libgl-xlib/meson.build
@@ -52,7 +52,7 @@ libgl = shared_library(
     libxlib, libws_xlib, libglapi_static,
     libgallium, libmesa_gallium, gallium_xlib_link_with,
   ],
-  dependencies : [dep_x11, dep_thread, dep_clock, dep_unwind, driver_swrast, driver_swr, driver_virgl, driver_asahi],
+  dependencies : [dep_x11, dep_thread, dep_clock, dep_unwind, driver_swrast, driver_swr, driver_virgl, driver_asahi, dep_a, dep_l],
   install : true,
   version : '1.5.0',
   darwin_versions: '4.0.0',
diff --git a/src/mesa/state_tracker/st_glsl_to_nir.cpp b/src/mesa/state_tracker/st_glsl_to_nir.cpp
index bf77064efb4..3171e62f0de 100644
--- a/src/mesa/state_tracker/st_glsl_to_nir.cpp
+++ b/src/mesa/state_tracker/st_glsl_to_nir.cpp
@@ -1007,10 +1007,12 @@ st_unpacked_uniforms_type_size(const struct glsl_type *type, bool bindless)
 void
 st_nir_lower_uniforms(struct st_context *st, nir_shader *nir)
 {
+   unsigned multiplier = 16;
    if (st->ctx->Const.PackedDriverUniformStorage) {
       NIR_PASS_V(nir, nir_lower_io, nir_var_uniform,
                  st_packed_uniforms_type_size,
                  (nir_lower_io_options)0);
+      multiplier = 4;
    } else {
       NIR_PASS_V(nir, nir_lower_io, nir_var_uniform,
                  st_unpacked_uniforms_type_size,
@@ -1018,9 +1020,7 @@ st_nir_lower_uniforms(struct st_context *st, nir_shader *nir)
    }
 
    if (nir->options->lower_uniforms_to_ubo)
-      NIR_PASS_V(nir, nir_lower_uniforms_to_ubo,
-                 st->ctx->Const.PackedDriverUniformStorage,
-                 !st->ctx->Const.NativeIntegers);
+      NIR_PASS_V(nir, nir_lower_uniforms_to_ubo, multiplier);
 }
 
 /* Last third of preparing nir from glsl, which happens after shader
